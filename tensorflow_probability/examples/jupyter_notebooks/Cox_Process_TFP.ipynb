{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cox_Process_TFP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "E5oAyLQts7gV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "n3snXNZOs7Td",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQ_e6powRlWh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Cox Process with TFP\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/cox_process_with_tfp.ipynb\"><img height=\"32px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/cox_process_with_tfp.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Original content [this Repository](https://github.com/blei-lab/edward/blob/master/examples/cox_process.py), created by [the Blei Lab](http://www.cs.columbia.edu/~blei/)\n",
        "\n",
        "Ported to [Tensorflow Probability](https://www.tensorflow.org/probability/) by Matthew McAteer ([`@MatthewMcAteer0`](https://twitter.com/MatthewMcAteer0)), with help from Bryan Seybold, Mike Shwe ([`@mikeshwe`](https://twitter.com/mikeshwe)), Josh Dillon, and the rest of the TFP team at  Google ([`tfprobability@tensorflow.org`](mailto:tfprobability@tensorflow.org)).\n",
        "\n",
        "---\n",
        "\n",
        "- [Dependencies & Prerequisites](#scrollTo=J21wYXBIbZq3)\n",
        "  - [Data](#scrollTo=vGg52VvSRlWm)\n",
        "  - [Model](#scrollTo=J808jVnDRlWo)\n",
        "  - [Inference](#scrollTo=q8SIkqvhRlWt)\n",
        "- [References](#scrollTo=Jq1b4fk6RlWx)"
      ]
    },
    {
      "metadata": {
        "id": "J21wYXBIbZq3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dependencies & Prerequisites"
      ]
    },
    {
      "metadata": {
        "id": "8rhrRpMWsxnR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Imports and Global Variables  { display-mode: \"form\" }\n",
        "!pip3 install -q observations\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)\n",
        "warning_status = \"ignore\" #@param [\"ignore\", \"always\", \"module\", \"once\", \"default\", \"error\"]\n",
        "import warnings\n",
        "warnings.filterwarnings(warning_status)\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(warning_status, category=DeprecationWarning)\n",
        "    warnings.filterwarnings(warning_status, category=UserWarning)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from datetime import datetime\n",
        "import os\n",
        "#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/))\n",
        "matplotlib_style = 'fivethirtyeight' #@param ['fivethirtyeight', 'bmh', 'ggplot', 'seaborn', 'default', 'Solarize_Light2', 'classic', 'dark_background', 'seaborn-colorblind', 'seaborn-notebook']\n",
        "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
        "import matplotlib.axes as axes;\n",
        "from matplotlib.patches import Ellipse\n",
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set_context('notebook')\n",
        "from IPython.core.pylabtools import figsize\n",
        "#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)\n",
        "notebook_screen_res = 'retina' #@param ['retina', 'png', 'jpeg', 'svg', 'pdf']\n",
        "%config InlineBackend.figure_format = notebook_screen_res\n",
        "\n",
        "import tensorflow as tf\n",
        "tfe = tf.contrib.eager\n",
        "\n",
        "# Eager Execution\n",
        "#@markdown Check the box below if you want to use [Eager Execution](https://www.tensorflow.org/guide/eager)\n",
        "#@markdown Eager execution provides An intuitive interface, Easier debugging, and a control flow comparable to Numpy. You can read more about it on the [Google AI Blog](https://ai.googleblog.com/2017/10/eager-execution-imperative-define-by.html)\n",
        "use_tf_eager = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Use try/except so we can easily re-execute the whole notebook.\n",
        "if use_tf_eager:\n",
        "  try:\n",
        "    tf.enable_eager_execution()\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "from tensorflow_probability import edward2 as ed\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "\n",
        "  \n",
        "def evaluate(tensors):\n",
        "  \"\"\"Evaluates Tensor or EagerTensor to Numpy `ndarray`s.\n",
        "  Args:\n",
        "  tensors: Object of `Tensor` or EagerTensor`s; can be `list`, `tuple`,\n",
        "    `namedtuple` or combinations thereof.\n",
        " \n",
        "  Returns:\n",
        "    ndarrays: Object with same structure as `tensors` except with `Tensor` or\n",
        "      `EagerTensor`s replaced by Numpy `ndarray`s.\n",
        "  \"\"\"\n",
        "  if tf.executing_eagerly():\n",
        "    return tf.contrib.framework.nest.pack_sequence_as(\n",
        "        tensors,\n",
        "        [t.numpy() if tf.contrib.framework.is_tensor(t) else t\n",
        "         for t in tf.contrib.framework.nest.flatten(tensors)])\n",
        "  return sess.run(tensors)\n",
        "\n",
        "class _TFColor(object):\n",
        "    \"\"\"Enum of colors used in TF docs.\"\"\"\n",
        "    red = '#F15854'\n",
        "    blue = '#5DA5DA'\n",
        "    orange = '#FAA43A'\n",
        "    green = '#60BD68'\n",
        "    pink = '#F17CB0'\n",
        "    brown = '#B2912F'\n",
        "    purple = '#B276B2'\n",
        "    yellow = '#DECF3F'\n",
        "    gray = '#4D4D4D'\n",
        "    def __getitem__(self, i):\n",
        "        return [\n",
        "            self.red,\n",
        "            self.orange,\n",
        "            self.green,\n",
        "            self.blue,\n",
        "            self.pink,\n",
        "            self.brown,\n",
        "            self.purple,\n",
        "            self.yellow,\n",
        "            self.gray,\n",
        "        ][i % 9]\n",
        "TFColor = _TFColor()\n",
        "\n",
        "def session_options(enable_gpu_ram_resizing=True, enable_xla=True):\n",
        "    \"\"\"\n",
        "    Allowing the notebook to make use of GPUs if they're available.\n",
        "    \n",
        "    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear \n",
        "    algebra that optimizes TensorFlow computations.\n",
        "    \"\"\"\n",
        "    config = tf.ConfigProto()\n",
        "    config.log_device_placement = True\n",
        "    if enable_gpu_ram_resizing:\n",
        "        # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
        "        # GPU. Otherwise the colab malloc's all GPU ram.\n",
        "        config.gpu_options.allow_growth = True\n",
        "    if enable_xla:\n",
        "        # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
        "        config.graph_options.optimizer_options.global_jit_level = (\n",
        "            tf.OptimizerOptions.ON_1)\n",
        "    return config\n",
        "\n",
        "\n",
        "def reset_sess(config=None):\n",
        "    \"\"\"\n",
        "    Convenience function to create the TF graph & session or reset them.\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = session_options()\n",
        "    global sess\n",
        "    tf.reset_default_graph()\n",
        "    try:\n",
        "        sess.close()\n",
        "    except:\n",
        "        pass\n",
        "    sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "class MVNCholPrecisionTriL(tfd.TransformedDistribution):\n",
        "  \"\"\"MVN from loc and (Cholesky) precision matrix.\"\"\"\n",
        "\n",
        "  def __init__(self, loc, chol_precision_tril, name=None):\n",
        "    super(MVNCholPrecisionTriL, self).__init__(\n",
        "        distribution=tfd.Independent(tfd.Normal(tf.zeros_like(loc),\n",
        "                                                scale=tf.ones_like(loc)),\n",
        "                                     reinterpreted_batch_ndims=1),\n",
        "        bijector=tfb.Chain([\n",
        "            tfb.Affine(shift=loc),\n",
        "            tfb.Invert(tfb.Affine(scale_tril=chol_precision_tril,\n",
        "                                  adjoint=True)),\n",
        "        ]),\n",
        "        name=name)\n",
        "\n",
        "reset_sess()\n",
        "\n",
        "# from edward.models import MultivariateNormalTriL, Normal, Poisson\n",
        "from scipy.stats import multivariate_normal, poisson"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "02KEEQ8URlWi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "### Cox vs. Poisson Point Processes\n",
        "\n",
        "A Cox Process is a variation on the  Poisson Point Process.\n",
        "\n",
        "Poisson Point Processes are useful for distributions of events that happen randomly. Consider the examples of banks going bust, busses arriving at bus stops, and calls coming into a call center. A poisson point process would be useful for modelling these, since you can specify how homogeneous or inhomogeneous the events are. You can create stochastic simulations of the timelines of these events, and where those events.\n",
        "\n",
        "However, We can go even further. What if not all events were the same. Suppose we wanted the time-dependent intensity itself to be modelled. This is what a Cox Process (named after the statistician [David Cox](https://en.wikipedia.org/wiki/David_Cox_(statistician)), who first published the model in 1955) is. Because of this double-stochasticity, a Cox process is sometimes known as a **doubly** stochastic Poisson process\n",
        "\n",
        "\n",
        "## Our example\n",
        "\n",
        "In our example, we're creating a Cox process model for spatial analysis ([Cox, 1955](https://www.jstor.org/stable/2983950?seq=1/subjects); Miller et al., 2014). The data set is a $N \\times V$ matrix. There are $N$ NBA players, $X = {(x_1, ..., x_N)}$, where each $x_n$ has a set of $V$ counts. $x_{n, v}$ is\n",
        "the number of attempted basketball shots for the $n$th NBA player at\n",
        "location $v$.\n",
        "\n",
        "We model a latent intensity function for each data point. Let $K$ be the\n",
        "$N \\times V \\times V$ covariance matrix applied to the data set $X$ with fixed\n",
        "kernel hyperparameters, where a slice $K_n$ is the $V \\times V$ covariance\n",
        "matrix over counts for a data point $x_n$.\n",
        "\n",
        "$ \\text{For } n = 1, ..., N $,\n",
        "\n",
        "$$ \\begin{align*} p(f_n) &= N(f_n | 0, K_n) \\text{,} \\\\\n",
        "p(x_{n,v} | f_{n, v}) &= \\text{Poisson}(x_{n,v} | \\text{exp}(f_{n,v})) \n",
        "\\end{align*}$$\n",
        "\n",
        "This gives us the formula for the probability of the number of attempted basketball shots for the the $n$th NBA player in total\n",
        "\n",
        "$$ \\begin{align*}\n",
        "p(x_n | f_n) &= \\prod_{v=1}^V p(x_{n,v} | f_{n,v}) \\text{,}\\\\\n",
        "  &= \\prod_{v=1}^V \\text{Poisson}(\\lambda= \\text{exp}(f_{n,v})) \n",
        "  \\end{align*}$$\n",
        "\n",
        "."
      ]
    },
    {
      "metadata": {
        "id": "3bmmX3sWRlWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Hyperparameters { run: \"auto\" }\n",
        "#@markdown Number of NBA players (default is 308)\n",
        "N = 308   #@param {type:\"slider\", min:100, max:350, step:1} \n",
        "#@markdown Number of shot locations (This notebook is optimized for 2)\n",
        "V = 2     #@param {type:\"slider\", min:2, max:4, step:1}\n",
        "\n",
        "shot_locations = []\n",
        "for v in range(V):\n",
        "  shot_locations.append(\"Location {}\".format(v+1))\n",
        "  \n",
        "nba_players = []\n",
        "for n in range(N):\n",
        "  nba_players.append(\"Player {}\".format(n+1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vGg52VvSRlWm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data"
      ]
    },
    {
      "metadata": {
        "id": "Idyl11R1RlWn",
        "colab_type": "code",
        "outputId": "8360f7c2-1b09-4493-cec3-a83b39026400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5287
        }
      },
      "cell_type": "code",
      "source": [
        "# Set seed. Remove this line to generate different mixtures!\n",
        "tf.set_random_seed(77)\n",
        "\n",
        "def build_toy_dataset(N, V):\n",
        "    \"\"\"\n",
        "    A simulator mimicking the data set from 2015-2016 NBA season with\n",
        "    308 NBA players and ~150,000 shots.\n",
        "    \"\"\"\n",
        "    L = np.tril(np.random.normal(2.5, 0.1, size=[V, V]))\n",
        "    K = np.matmul(L, L.T)\n",
        "    x = np.zeros([N, V])\n",
        "    for n in range(N):\n",
        "        f_n = multivariate_normal.rvs(cov=K, size=1)\n",
        "        for v in range(V):\n",
        "            x[n, v] = poisson.rvs(mu=np.exp(f_n[v]), size=1)\n",
        "\n",
        "    return x\n",
        "\n",
        "x_data = build_toy_dataset(N, V)\n",
        "x_data = x_data.astype(np.float32)\n",
        "pd.options.display.float_format = '{:20,.0f}'.format\n",
        "pd.set_option('display.max_rows', N)\n",
        "print(\"Our toy dataset (Rows = Players, Columns = Court Positions) \")\n",
        "print(pd.DataFrame(x_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our toy dataset (Rows = Players, Columns = Court Positions) \n",
            "                       0                    1\n",
            "0                      6                    2\n",
            "1                      0                    2\n",
            "2                      0                    0\n",
            "3                      4                   35\n",
            "4                      7                   80\n",
            "5                      0                    0\n",
            "6                      5                   19\n",
            "7                      5                    3\n",
            "8                      0                    5\n",
            "9                     40                   68\n",
            "10                     7                  217\n",
            "11                    52                  104\n",
            "12                     2                    0\n",
            "13                    56                   72\n",
            "14                     0                    0\n",
            "15                     0                    0\n",
            "16                     0                    2\n",
            "17                     3                    2\n",
            "18                    58                  214\n",
            "19                     2                    1\n",
            "20                     1                    0\n",
            "21                     1                    0\n",
            "22                     0                    1\n",
            "23                     1                    0\n",
            "24                     0                    1\n",
            "25                     0                    0\n",
            "26                     0                    1\n",
            "27                     0                    1\n",
            "28                     7                    0\n",
            "29                    24               15,270\n",
            "30                     3                    0\n",
            "31                    13                   71\n",
            "32                     0                    0\n",
            "33                   193                   77\n",
            "34                    39                  102\n",
            "35                    13                    5\n",
            "36                     4                    5\n",
            "37                     1                    0\n",
            "38                     0                    2\n",
            "39                     0                  123\n",
            "40                    55                  218\n",
            "41                    18                   25\n",
            "42                     1                    2\n",
            "43                     0                    5\n",
            "44                    26                    4\n",
            "45                     1                    1\n",
            "46                     1                    0\n",
            "47                     8                  119\n",
            "48                    23                  276\n",
            "49                    32                   15\n",
            "50                     5                  114\n",
            "51                     0                    1\n",
            "52                     0                    0\n",
            "53                     0                    1\n",
            "54                     0                    1\n",
            "55                     0                    9\n",
            "56                     0                    1\n",
            "57                     0                    0\n",
            "58                     0                    0\n",
            "59                     0                    0\n",
            "60                     4                    0\n",
            "61                    18                    0\n",
            "62                     0                    0\n",
            "63                   529                   43\n",
            "64                     0                    0\n",
            "65                    27                   48\n",
            "66                     2                    2\n",
            "67                     1                    0\n",
            "68                     0                    0\n",
            "69                     2                    0\n",
            "70                     3                    0\n",
            "71                     0                    0\n",
            "72                     0                    0\n",
            "73                     1                    0\n",
            "74                     0                    0\n",
            "75                    21                  318\n",
            "76                     5                    2\n",
            "77                     0                    0\n",
            "78                     6                    3\n",
            "79                     2                    0\n",
            "80                     3                   26\n",
            "81                     0                    5\n",
            "82                     0                    0\n",
            "83                     4                   50\n",
            "84                     1                    6\n",
            "85                     1                    1\n",
            "86                     0                    0\n",
            "87                    84                  616\n",
            "88                    14                   40\n",
            "89                     4                   32\n",
            "90                     0                    0\n",
            "91                     0                   18\n",
            "92                   273                  280\n",
            "93                     0                    0\n",
            "94                     1                    0\n",
            "95                     0                    0\n",
            "96                     0                    0\n",
            "97                    11                  148\n",
            "98                     0                    0\n",
            "99                     0                    0\n",
            "100                    1                    4\n",
            "101                    1                    0\n",
            "102                   17                    9\n",
            "103                    0                   23\n",
            "104                    0                    0\n",
            "105                    3                    0\n",
            "106                    4                   22\n",
            "107                    1                   10\n",
            "108                    0                   14\n",
            "109                   24                    5\n",
            "110                    9                   51\n",
            "111                   74                   78\n",
            "112                    0                    8\n",
            "113                    0                    0\n",
            "114                    1                    4\n",
            "115                    1                    3\n",
            "116                   12                  173\n",
            "117                   96                  310\n",
            "118                    0                    0\n",
            "119                    1                    4\n",
            "120                    8                    8\n",
            "121                   22                   17\n",
            "122                    0                    0\n",
            "123                    4                   47\n",
            "124                    1                   13\n",
            "125                   12                    0\n",
            "126                    0                    0\n",
            "127                    1                    1\n",
            "128                    0                    4\n",
            "129                    3                    0\n",
            "130                    0                    1\n",
            "131                    1                    2\n",
            "132                    4                    0\n",
            "133                    4                    2\n",
            "134                   17                    2\n",
            "135                    1                    3\n",
            "136                    0                    9\n",
            "137                   11                1,292\n",
            "138                    0                    0\n",
            "139                    2                    0\n",
            "140                    2                   12\n",
            "141                    5                    2\n",
            "142                    0                    4\n",
            "143                    2                   62\n",
            "144                    0                    0\n",
            "145                   64                  114\n",
            "146                    0                    0\n",
            "147                    0                    0\n",
            "148                    0                    0\n",
            "149                    2                    3\n",
            "150                   31                   50\n",
            "151                    0                   29\n",
            "152                    0                    1\n",
            "153                   39                    1\n",
            "154                    5                   77\n",
            "155                   18                   38\n",
            "156                    0                    0\n",
            "157                   10                    6\n",
            "158                  176                    9\n",
            "159                    3                    5\n",
            "160                    2                    8\n",
            "161                    0                    0\n",
            "162                    0                   58\n",
            "163                    0                    0\n",
            "164                   22                  569\n",
            "165                   11                    1\n",
            "166                    3                    3\n",
            "167                    1                    0\n",
            "168                    0                    0\n",
            "169                  164                  184\n",
            "170                    3                    5\n",
            "171                    0                    0\n",
            "172                    6                    5\n",
            "173                    0                    0\n",
            "174                    2                1,254\n",
            "175                    4                   89\n",
            "176                    2                    1\n",
            "177                    0                    0\n",
            "178                    2                    0\n",
            "179                    0                    0\n",
            "180                    3                   10\n",
            "181                    6                    3\n",
            "182                    0                    0\n",
            "183                    3                    0\n",
            "184                   24                    0\n",
            "185                   30                   22\n",
            "186                  107                    0\n",
            "187                    2                  303\n",
            "188                    2                    0\n",
            "189                    1                    0\n",
            "190                    9                    0\n",
            "191                    0                    0\n",
            "192                   90                   54\n",
            "193                    0                    0\n",
            "194                    3                    3\n",
            "195                   83                   19\n",
            "196                    0                    6\n",
            "197                    1                    0\n",
            "198                   12                    2\n",
            "199                    6                    4\n",
            "200                    0                    2\n",
            "201                    0                    0\n",
            "202                    0                    0\n",
            "203                    3                    4\n",
            "204                    0                    2\n",
            "205                    0                    0\n",
            "206                    0                    0\n",
            "207                    2                    0\n",
            "208                    0                    0\n",
            "209                    0                    0\n",
            "210                    1                    4\n",
            "211                    0                    0\n",
            "212                    3                    0\n",
            "213                    0                    0\n",
            "214                    2                  185\n",
            "215                    0                    1\n",
            "216                  147                6,028\n",
            "217                   18                    0\n",
            "218                    0                    0\n",
            "219                  266                  236\n",
            "220                    1                    0\n",
            "221                    0                    0\n",
            "222                    1                    0\n",
            "223                    0                    0\n",
            "224                    0                    2\n",
            "225                    0                    0\n",
            "226                    0                    1\n",
            "227                    1                    3\n",
            "228                    0                    0\n",
            "229                    0                    0\n",
            "230                    4                    0\n",
            "231                   28                  830\n",
            "232                    0                    0\n",
            "233                    0                    1\n",
            "234                   17                   94\n",
            "235                   21                  735\n",
            "236                    0                    0\n",
            "237                   28                  115\n",
            "238                    0                    0\n",
            "239                    1                    1\n",
            "240                    0                    9\n",
            "241                    1                    6\n",
            "242                    1                    0\n",
            "243                    1                    6\n",
            "244                   29                   17\n",
            "245                    0                    4\n",
            "246                    2                    6\n",
            "247                    2                    5\n",
            "248                    3                    0\n",
            "249                    0                    0\n",
            "250                    5                   33\n",
            "251                    0                    0\n",
            "252                    0                    0\n",
            "253                    0                    0\n",
            "254                   21                    5\n",
            "255                    0                    3\n",
            "256                   90                6,977\n",
            "257                    0                    1\n",
            "258                    2                    0\n",
            "259                    0                    3\n",
            "260                   15                    0\n",
            "261                    0                    0\n",
            "262                    6                    2\n",
            "263                    8                   39\n",
            "264                    0                    1\n",
            "265                    0                    0\n",
            "266                    0                    1\n",
            "267                    5                   67\n",
            "268                    0                    0\n",
            "269                    0                    0\n",
            "270                    0                    0\n",
            "271                    0                    0\n",
            "272                   38                    5\n",
            "273                    0                    0\n",
            "274                    0                    2\n",
            "275                    0                    1\n",
            "276                    0                    0\n",
            "277                    1                  465\n",
            "278                    7                    1\n",
            "279                   25                  457\n",
            "280                    0                    0\n",
            "281                    0                    0\n",
            "282                    0                    1\n",
            "283                   21                   13\n",
            "284                   50                   11\n",
            "285                   32                   12\n",
            "286                   11                    0\n",
            "287                    0                    0\n",
            "288                    0                    0\n",
            "289                    0                    0\n",
            "290                    0                    0\n",
            "291                    0                    0\n",
            "292                  129                    4\n",
            "293                    3                    2\n",
            "294                    0                    1\n",
            "295                    0                    0\n",
            "296                  151                5,968\n",
            "297                    1                    1\n",
            "298                    0                    0\n",
            "299                  493                  452\n",
            "300                  149                   23\n",
            "301                    0                   24\n",
            "302                    0                    4\n",
            "303                    0                    0\n",
            "304                  244                   18\n",
            "305                   63                  163\n",
            "306                    5                    6\n",
            "307                    2                1,543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J808jVnDRlWo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "So for our point process, we want to be able to simulate one fo these $N \\times V$ datasets, which we can do with a latent intensity function $f$. This will be a multivariate normal distribution for which we calculate the covariance for every single NBA player across all of the positions they made shots from (not all players are going to be equal when it comes to which position they're best from).  The outputs of this function will then be fed\n",
        "\n",
        "We model a latent intensity function for each data point. Let $K$ be the\n",
        "$N \\times V \\times V$ covariance matrix applied to the data set $X$ with fixed\n",
        "kernel hyperparameters, where a slice $K_n$ is the $V \\times V$ covariance\n",
        "matrix over counts for a data point $x_n$.\n",
        "\n",
        "$ \\text{For } n = 1, ..., N$  (with $N$ being the number of players),\n",
        "\n",
        "$$ p(f_n) = N(f_n | 0, K_n) \\text{,} $$"
      ]
    },
    {
      "metadata": {
        "id": "H5q3GGNU-yiI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First we need to define the Radial basis function kernel, also known as the squared exponential or exponentiated quadratic:\n",
        "\n",
        "It is defined as $k(x, x') = \\sigma^2 \\exp\\Big(-\\ \\frac{1}{2} \\sum_{d=1}^D \\ \\frac{1}{\\ell_d^2} (x_d - x'_d)^2 \\Big)$ for output variance $\\sigma^2$ and lengthscale $\\ell^2$.\n",
        "  \n",
        "The kernel is evaluated over all pairs of rows, `k(X[i, ], X2[j, ])`. If `X2` is not specified, then it evaluates over all pairs of rows in `X`, `k(X[i, ], X[j, ])`. The output is a matrix where each entry (`i`, `j`) is the kernel over the `i`th and `j`th rows.\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "CkPfDPvF-URf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title RBF Function Definition  { display-mode: \"form\" }\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "def rbf(X, X2=None, lengthscale=1.0, variance=1.0):\n",
        "    \"\"\"Radial basis function kernel\n",
        "    Args:\n",
        "        X: tf.Tensor.\n",
        "            N x D matrix of N data points each with D features.\n",
        "        X2: tf.Tensor.\n",
        "            N x D matrix of N data points each with D features.\n",
        "        lengthscale: tf.Tensor.\n",
        "            Lengthscale parameter, a positive scalar or D-dimensional vector.\n",
        "        variance: tf.Tensor.\n",
        "            Output variance parameter, a positive scalar.\n",
        "    \"\"\"\n",
        "    lengthscale = tf.convert_to_tensor(lengthscale)\n",
        "    variance = tf.convert_to_tensor(variance)\n",
        "    dependencies = [tf.assert_positive(lengthscale),\n",
        "                    tf.assert_positive(variance)]\n",
        "    lengthscale = control_flow_ops.with_dependencies(dependencies, lengthscale)\n",
        "    variance = control_flow_ops.with_dependencies(dependencies, variance)\n",
        "\n",
        "    X = tf.convert_to_tensor(X)\n",
        "    X = X / lengthscale\n",
        "    Xs = tf.reduce_sum(tf.square(X), 1)\n",
        "    if X2 is None:\n",
        "        X2 = X\n",
        "        X2s = Xs\n",
        "    else:\n",
        "        X2 = tf.convert_to_tensor(X2)\n",
        "        X2 = X2 / lengthscale\n",
        "        X2s = tf.reduce_sum(tf.square(X2), 1)\n",
        "\n",
        "    square = tf.reshape(Xs, [-1, 1]) + tf.reshape(X2s, [1, -1]) - \\\n",
        "        2 * tf.matmul(X, X2, transpose_b=True)\n",
        "    output = variance * tf.exp(-square / 2)\n",
        "    return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFOmMDog1_eJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can get to defining our model. We're going to define our Distribution for our point process, $f$, as a multivariate normal distribution. From here, we feed random samples from that into a Poisson Distribution"
      ]
    },
    {
      "metadata": {
        "id": "jsgradHqRlWp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Form (N, V, V) covariance, one matrix per data point.\n",
        "K = tf.stack([rbf(tf.reshape(xn, [V, 1])) + tf.diag(tf.fill([V], 1e-6))\n",
        "                for xn in tf.unstack(x_data)])\n",
        "\n",
        "# Creating our Covariance Matrix\n",
        "f = tfd.MultivariateNormalTriL(loc=tf.zeros([N, V]),\n",
        "                               scale_tril=tf.cholesky(K))\n",
        "\n",
        "# Feeding the latent function into a Poisson Distribution\n",
        "x_init = tfd.Poisson(rate=tf.exp(f.sample()))\n",
        "x_model = tfd.Poisson(rate=tf.exp(f.sample()))\n",
        "\n",
        "# Getting our initial parametrization tensor for setting up the \n",
        "# trainable_distribution\n",
        "x_ = evaluate(x_init.sample())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8SIkqvhRlWt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Inference\n",
        "\n",
        "Based on this, we're going to take our prior, and use this to infer a normal distribution distribution. \n",
        "\n",
        "For this inference, we first need to define our trainable distributions. This will be a version of `tfd.MultivariateNormalTrill` that we will be able to parameterize with just one tensor. We can then improve the fit using using `tf.train` optimizers (or potentially even `tfp.optimizers`)"
      ]
    },
    {
      "metadata": {
        "id": "7rd2JqiVC6_w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def softplus_and_shift(x, shift=1e-5, name=None):\n",
        "  \"\"\"Converts (batch of) scalars to (batch of) positive valued scalars.\n",
        "  Args:\n",
        "    x: (Batch of) `float`-like `Tensor` representing scalars which will be\n",
        "      transformed into positive elements.\n",
        "    shift: `Tensor` added to `softplus` transformation of elements.\n",
        "      Default value: `1e-5`.\n",
        "    name: A `name_scope` name for operations created by this function.\n",
        "      Default value: `None` (i.e., \"positive_tril_with_shift\").\n",
        "  Returns:\n",
        "    scale: (Batch of) scalars`with `x.dtype` and `x.shape`.\n",
        "  \"\"\"\n",
        "  x = tf.convert_to_tensor(x, name='x')\n",
        "  y = tf.nn.softplus(x)\n",
        "  if shift is not None:\n",
        "      y += shift\n",
        "  return y\n",
        "\n",
        "\n",
        "def tril_with_diag_softplus_and_shift(x, diag_shift=1e-5, name=None):\n",
        "  \"\"\"Converts (batch of) vectors to (batch of) lower-triangular scale matrices.\n",
        "  Args:\n",
        "    x: (Batch of) `float`-like `Tensor` representing vectors which will be\n",
        "      transformed into lower-triangular scale matrices with positive diagonal\n",
        "      elements. Rightmost shape `n` must be such that\n",
        "      `n = dims * (dims + 1) / 2` for some positive, integer `dims`.\n",
        "    diag_shift: `Tensor` added to `softplus` transformation of diagonal\n",
        "      elements.\n",
        "      Default value: `1e-5`.\n",
        "    name: A `name_scope` name for operations created by this function.\n",
        "      Default value: `None` (i.e., \"tril_with_diag_softplus_and_shift\").\n",
        "  Returns:\n",
        "    scale_tril: (Batch of) lower-triangular `Tensor` with `x.dtype` and\n",
        "      rightmost shape `[dims, dims]` where `n = dims * (dims + 1) / 2` where\n",
        "      `n = x.shape[-1]`.\n",
        "  \"\"\"\n",
        "  with tf.name_scope(name, 'tril_with_diag_softplus_and_shift',\n",
        "                     [x, diag_shift]):\n",
        "      x = tf.convert_to_tensor(x, name='x')\n",
        "      x = tfd.fill_triangular(x)\n",
        "      diag = softplus_and_shift(tf.matrix_diag_part(x), diag_shift)\n",
        "      x = tf.matrix_set_diag(x, diag)\n",
        "      return x\n",
        "\n",
        "\n",
        "def trainable_multivariate_normal_tril(x, dims, layer_fn=tf.layers.dense,\n",
        "    loc_fn=lambda x: x, scale_fn=tril_with_diag_softplus_and_shift,\n",
        "    name=None):\n",
        "  \"\"\"Constructs a trainable `tfd.MultivariateNormalTriL` distribution.\n",
        "  Args:\n",
        "    x: `Tensor` with floating type. Must have statically defined rank and\n",
        "      statically known right-most dimension.\n",
        "    dims: Scalar, `int`, `Tensor` indicated the MVN event size, i.e., the\n",
        "      created MVN will be distribution over length-`dims` vectors.\n",
        "    layer_fn: Python `callable` which takes input `x` and `int` scalar `d` and\n",
        "      returns a transformation of `x` with shape\n",
        "      `tf.concat([tf.shape(x)[:-1], [d]], axis=0)`.\n",
        "      Default value: `tf.layers.dense`.\n",
        "    loc_fn: Python `callable` which transforms the `loc` parameter. Takes a\n",
        "      (batch of) length-`dims` vectors and returns a `Tensor` of same shape and\n",
        "      `dtype`.\n",
        "      Default value: `lambda x: x`.\n",
        "    scale_fn: Python `callable` which transforms the `scale` parameters. Takes a\n",
        "      (batch of) length-`dims * (dims + 1) / 2` vectors and returns a\n",
        "      lower-triangular `Tensor` of same batch shape with rightmost dimensions\n",
        "      having shape `[dims, dims]`.\n",
        "      Default value: `tril_with_diag_softplus_and_shift`.\n",
        "    name: A `name_scope` name for operations created by this function.\n",
        "      Default value: `None` (i.e., \"multivariate_normal_tril\").\n",
        "  Returns:\n",
        "    mvntril: An instance of `tfd.MultivariateNormalTriL`.\n",
        "  \"\"\"\n",
        "  x = tf.convert_to_tensor(x, name='x')\n",
        "  x = layer_fn(x, dims + dims * (dims + 1) // 2)\n",
        "  return tfd.MultivariateNormalTriL(\n",
        "      loc=loc_fn(x[..., :dims]),\n",
        "      scale_tril=scale_fn(x[..., dims:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B740-KtyDm-z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can run our actual inference, and improve the parameters for $qf$."
      ]
    },
    {
      "metadata": {
        "id": "QEHWSo5OTWIA",
        "colab_type": "code",
        "outputId": "06805af8-3482-45cd-82cf-b928cc646b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "# Build TF graph for fitting MVNTriL maximum likelihood estimator.\n",
        "qf = trainable_multivariate_normal_tril(x_, dims=V)\n",
        "kl = tf.reduce_mean(qf.kl_divergence(f))\n",
        "loss = -tf.reduce_mean(qf.log_prob(x_data))\n",
        "elbo = loss + kl\n",
        "train_op = tf.train.AdamOptimizer(learning_rate=2.**-3).minimize(elbo)\n",
        "mse = tf.reduce_mean(tf.squared_difference(x_data, qf.mean()))\n",
        "init_op = tf.global_variables_initializer()\n",
        "\n",
        "# Run graph 5000 times.\n",
        "num_steps = 50000\n",
        "elbo_ = evaluate(tf.zeros(num_steps)) # Style: `_` to indicate evaluate result.\n",
        "mse_ = evaluate(tf.zeros(num_steps))\n",
        "kl_ = evaluate(tf.zeros(num_steps))\n",
        "\n",
        "evaluate(init_op)\n",
        "for it in range(elbo_.size):\n",
        "    _, elbo_[it], mse_[it], kl_[it] = evaluate([train_op, elbo, mse, kl])\n",
        "    if it % 2000 == 0 or it == elbo_.size - 1:\n",
        "        print(\"iteration:{}  elbo:{:.6f}  mse:{:.6f}  KL divergence:{:.6f}\".format(it, elbo_[it], mse_[it], kl_[it]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration:0  elbo:235717183668224.000000  mse:590671.125000  KL divergence:1626973.750000\n",
            "iteration:2000  elbo:21641766.000000  mse:590706.312500  KL divergence:21396096.000000\n",
            "iteration:4000  elbo:14370678.000000  mse:591073.437500  KL divergence:14124876.000000\n",
            "iteration:6000  elbo:13340787.000000  mse:591261.312500  KL divergence:13094784.000000\n",
            "iteration:8000  elbo:12783556.000000  mse:591295.812500  KL divergence:12537099.000000\n",
            "iteration:10000  elbo:11454258.000000  mse:591325.000000  KL divergence:11206598.000000\n",
            "iteration:12000  elbo:8651038.000000  mse:591316.375000  KL divergence:8400160.000000\n",
            "iteration:14000  elbo:4329554.000000  mse:591292.187500  KL divergence:4069961.250000\n",
            "iteration:16000  elbo:1233809.750000  mse:591288.250000  KL divergence:951596.375000\n",
            "iteration:18000  elbo:646732.500000  mse:591288.187500  KL divergence:322155.781250\n",
            "iteration:20000  elbo:506378.687500  mse:591288.187500  KL divergence:179520.453125\n",
            "iteration:22000  elbo:429994.156250  mse:591288.187500  KL divergence:168811.812500\n",
            "iteration:24000  elbo:399218.687500  mse:591288.062500  KL divergence:181622.296875\n",
            "iteration:26000  elbo:394190.875000  mse:591285.937500  KL divergence:204707.812500\n",
            "iteration:28000  elbo:389333.250000  mse:591285.562500  KL divergence:181781.484375\n",
            "iteration:30000  elbo:389868.437500  mse:591272.000000  KL divergence:183740.906250\n",
            "iteration:32000  elbo:412555.437500  mse:591250.937500  KL divergence:199735.078125\n",
            "iteration:34000  elbo:387224.375000  mse:591167.625000  KL divergence:185780.296875\n",
            "iteration:36000  elbo:390239.593750  mse:591081.687500  KL divergence:206908.156250\n",
            "iteration:38000  elbo:451339.156250  mse:591023.187500  KL divergence:289509.218750\n",
            "iteration:40000  elbo:399503.000000  mse:591028.750000  KL divergence:215555.359375\n",
            "iteration:42000  elbo:500596.375000  mse:591027.437500  KL divergence:395535.531250\n",
            "iteration:44000  elbo:389444.718750  mse:590979.312500  KL divergence:188720.671875\n",
            "iteration:46000  elbo:385149.312500  mse:591013.375000  KL divergence:193938.812500\n",
            "iteration:48000  elbo:451350.312500  mse:591006.750000  KL divergence:268267.218750\n",
            "iteration:49999  elbo:389895.187500  mse:591019.312500  KL divergence:214850.937500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MJJahpN7noKN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And now we finally have our final process, the one we defined earlier as"
      ]
    },
    {
      "metadata": {
        "id": "F1ROkrIPnnaf",
        "colab_type": "code",
        "outputId": "ed41073c-8037-4641-f60e-c72032d75b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#x_cox = tfd.Poisson(rate=tf.exp(qf.sample()))\n",
        "x_cox = tfd.Poisson(rate=qf.sample())\n",
        "print(x_cox)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfp.distributions.Poisson(\"Poisson_2/\", batch_shape=(308, 2), event_shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KNXyMYW-n7M2",
        "colab_type": "code",
        "outputId": "942bc10f-36f6-4be4-980e-3dcea77a2d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5287
        }
      },
      "cell_type": "code",
      "source": [
        "x_simulated = evaluate(x_cox.sample()).astype(np.float)\n",
        "pd.options.display.float_format = '{:20,.0f}'.format\n",
        "pd.set_option('display.max_rows', N)\n",
        "print(\"Our Cox-Process-Simulated dataset (Rows = Players, Columns = Court Positions) \")\n",
        "print(pd.DataFrame(x_simulated, columns=list('AB')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our Cox-Process-Simulated dataset (Rows = Players, Columns = Court Positions) \n",
            "                       A                    B\n",
            "0                      0                    0\n",
            "1                      0                    6\n",
            "2                      0                    0\n",
            "3                      0                    0\n",
            "4                      0                    0\n",
            "5                      2                    0\n",
            "6                      0                    0\n",
            "7                    171                  166\n",
            "8                      0                    0\n",
            "9                      2                    1\n",
            "10                     0                    0\n",
            "11                     3                    3\n",
            "12                     0                    0\n",
            "13                    30                   34\n",
            "14                     0                    1\n",
            "15                     1                    3\n",
            "16                     0                    0\n",
            "17                     0                    0\n",
            "18                     2                    4\n",
            "19                     0                    0\n",
            "20                     0                    0\n",
            "21                     0                    0\n",
            "22                     0                    0\n",
            "23                     0                   11\n",
            "24                     0                    3\n",
            "25                     0                    0\n",
            "26                     3                    2\n",
            "27                    17                   15\n",
            "28                     7                    5\n",
            "29                    10                    0\n",
            "30                    10                    0\n",
            "31                    25                   13\n",
            "32                     3                    7\n",
            "33                     0                    0\n",
            "34                     0                    0\n",
            "35                     0                    0\n",
            "36                    15                   19\n",
            "37                     7                   15\n",
            "38                     7                    8\n",
            "39                     0                    0\n",
            "40                     8                   11\n",
            "41                     0                    0\n",
            "42                     0                    0\n",
            "43                    18                   18\n",
            "44                     0                    2\n",
            "45                     0                    0\n",
            "46                     0                    0\n",
            "47                    19                   20\n",
            "48                     0                    0\n",
            "49                     0                    0\n",
            "50                     1                    9\n",
            "51                     0                   11\n",
            "52                     0                    0\n",
            "53                     0                    1\n",
            "54                    24                   15\n",
            "55                     0                    0\n",
            "56                     0                    0\n",
            "57                    15                   10\n",
            "58                    60                   41\n",
            "59                     5                    5\n",
            "60                     0                    0\n",
            "61                     0                    0\n",
            "62                    26                   33\n",
            "63                     0                    0\n",
            "64                    10                    5\n",
            "65                     0                   19\n",
            "66                    12                   15\n",
            "67                     0                    0\n",
            "68                     0                    0\n",
            "69                     0                    4\n",
            "70                     7                   11\n",
            "71                     0                    0\n",
            "72                     6                    9\n",
            "73                     0                    0\n",
            "74                     0                    0\n",
            "75                     1                    0\n",
            "76                     0                    1\n",
            "77                     0                    0\n",
            "78                    52                   51\n",
            "79                     0                    0\n",
            "80                     0                    0\n",
            "81                    12                    9\n",
            "82                     0                    0\n",
            "83                    44                   37\n",
            "84                     0                    0\n",
            "85                     0                    0\n",
            "86                     0                    0\n",
            "87                    11                   15\n",
            "88                     2                    4\n",
            "89                     0                    0\n",
            "90                     0                    0\n",
            "91                     0                    0\n",
            "92                    14                    7\n",
            "93                     0                    0\n",
            "94                    41                   48\n",
            "95                     4                    2\n",
            "96                     8                    6\n",
            "97                     0                   14\n",
            "98                     1                    5\n",
            "99                     4                    3\n",
            "100                    1                    4\n",
            "101                    0                    0\n",
            "102                   19                   12\n",
            "103                    4                    1\n",
            "104                    2                    0\n",
            "105                    0                    0\n",
            "106                    5                    0\n",
            "107                    0                    0\n",
            "108                    0                    1\n",
            "109                   26                    0\n",
            "110                    0                    0\n",
            "111                    6                   20\n",
            "112                    0                    0\n",
            "113                   25                   21\n",
            "114                    0                    0\n",
            "115                    3                    7\n",
            "116                    0                    0\n",
            "117                    0                    1\n",
            "118                   15                   13\n",
            "119                   19                   12\n",
            "120                   17                   10\n",
            "121                    0                   13\n",
            "122                    5                    5\n",
            "123                    0                    0\n",
            "124                   21                   29\n",
            "125                    2                    4\n",
            "126                    0                    0\n",
            "127                    0                    0\n",
            "128                    0                    0\n",
            "129                    0                    4\n",
            "130                    0                    0\n",
            "131                   50                   39\n",
            "132                    0                    0\n",
            "133                   48                   38\n",
            "134                    8                    4\n",
            "135                    0                    0\n",
            "136                   23                   21\n",
            "137                    2                    0\n",
            "138                    9                    6\n",
            "139                   18                   17\n",
            "140                    0                    0\n",
            "141                    0                    0\n",
            "142                    0                    0\n",
            "143                    0                    0\n",
            "144                    0                    0\n",
            "145                    0                    0\n",
            "146                    0                    0\n",
            "147                    4                    6\n",
            "148                    0                    0\n",
            "149                    1                    4\n",
            "150                    7                   18\n",
            "151                    0                    0\n",
            "152                    6                    4\n",
            "153                    0                    0\n",
            "154                    4                    7\n",
            "155                    0                    0\n",
            "156                   14                   21\n",
            "157                   18                   31\n",
            "158                    8                   14\n",
            "159                    0                    0\n",
            "160                    0                    0\n",
            "161                    4                    3\n",
            "162                    0                    0\n",
            "163                    0                    0\n",
            "164                    0                    0\n",
            "165                    0                    0\n",
            "166                    0                    0\n",
            "167                    8                    7\n",
            "168                    3                    7\n",
            "169                   12                   16\n",
            "170                    0                    0\n",
            "171                    1                    4\n",
            "172                    0                    0\n",
            "173                   13                   18\n",
            "174                   11                   14\n",
            "175                    4                    2\n",
            "176                    0                    0\n",
            "177                    0                    0\n",
            "178                    0                    0\n",
            "179                    5                   17\n",
            "180                   11                   10\n",
            "181                    0                    0\n",
            "182                    0                    0\n",
            "183                    5                    3\n",
            "184                   17                   18\n",
            "185                    0                    0\n",
            "186                    7                    3\n",
            "187                    0                    0\n",
            "188                    0                    0\n",
            "189                    0                    0\n",
            "190                    0                    0\n",
            "191                    0                    0\n",
            "192                    2                    0\n",
            "193                    0                    0\n",
            "194                    6                    6\n",
            "195                   14                   16\n",
            "196                    0                    0\n",
            "197                   27                   23\n",
            "198                    0                    0\n",
            "199                    8                   11\n",
            "200                    0                    3\n",
            "201                    8                   25\n",
            "202                    0                    0\n",
            "203                    0                    0\n",
            "204                    8                    9\n",
            "205                    7                   10\n",
            "206                    2                    3\n",
            "207                    3                    5\n",
            "208                    0                    0\n",
            "209                    0                    0\n",
            "210                   24                   34\n",
            "211                    0                    0\n",
            "212                    7                    2\n",
            "213                    0                    0\n",
            "214                    0                    0\n",
            "215                    0                    0\n",
            "216                    0                    0\n",
            "217                    0                    0\n",
            "218                    8                    4\n",
            "219                    7                   13\n",
            "220                    5                   23\n",
            "221                    0                    0\n",
            "222                   19                   10\n",
            "223                    1                   14\n",
            "224                    8                    0\n",
            "225                   12                    7\n",
            "226                   28                   48\n",
            "227                   11                    9\n",
            "228                   40                   22\n",
            "229                    0                    0\n",
            "230                    9                    9\n",
            "231                    0                    0\n",
            "232                    0                    0\n",
            "233                   29                   22\n",
            "234                    0                    0\n",
            "235                    8                   11\n",
            "236                   14                    3\n",
            "237                   14                   14\n",
            "238                   17                   19\n",
            "239                    1                    0\n",
            "240                    0                    0\n",
            "241                    5                    7\n",
            "242                    9                    8\n",
            "243                    7                    7\n",
            "244                    0                    0\n",
            "245                   31                   23\n",
            "246                    0                    0\n",
            "247                    0                    0\n",
            "248                    0                    0\n",
            "249                    0                    4\n",
            "250                    0                    0\n",
            "251                   20                    7\n",
            "252                    6                    4\n",
            "253                    2                    3\n",
            "254                   13                   15\n",
            "255                    8                    8\n",
            "256                    7                    9\n",
            "257                   10                    4\n",
            "258                    0                    0\n",
            "259                   12                   13\n",
            "260                    0                    0\n",
            "261                    0                    0\n",
            "262                   38                   28\n",
            "263                    6                    7\n",
            "264                    0                    0\n",
            "265                    2                   10\n",
            "266                    0                    0\n",
            "267                    9                   17\n",
            "268                   12                    9\n",
            "269                    0                    0\n",
            "270                    0                    0\n",
            "271                    0                    0\n",
            "272                    0                    0\n",
            "273                    0                    0\n",
            "274                   11                   27\n",
            "275                    0                    7\n",
            "276                    0                    0\n",
            "277                    0                    1\n",
            "278                    0                    0\n",
            "279                    9                   12\n",
            "280                    0                    6\n",
            "281                   13                   13\n",
            "282                   36                   26\n",
            "283                   25                   16\n",
            "284                    6                   10\n",
            "285                    3                    3\n",
            "286                    0                    0\n",
            "287                    6                    9\n",
            "288                    5                    0\n",
            "289                    0                    0\n",
            "290                    1                    2\n",
            "291                    0                    0\n",
            "292                    0                    0\n",
            "293                    4                    4\n",
            "294                    0                    0\n",
            "295                   42                   40\n",
            "296                   14                   10\n",
            "297                   23                    8\n",
            "298                    0                    0\n",
            "299                    8                    8\n",
            "300                    0                    0\n",
            "301                    0                    0\n",
            "302                    8                   15\n",
            "303                    0                    0\n",
            "304                    0                    0\n",
            "305                    8                   11\n",
            "306                   17                   16\n",
            "307                    0                    0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0_JoSEHD-nPB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "And there we have it. We now have a Cox point process for simulating numbers of shots taken by NBA players from two given positions on the court. The range of these values is very similar to our original data (which we would expect, after creating our new doubly-stochastic process based on the ELBO loss that takes in the previous distribution and `x_data` itself).\n",
        "\n",
        "As we can see, we can use the Cox Process to model phenomena more complex than simpler Poisson point processes. For example, Cox processes are used in neurology researchto generate simulations of spike trains (the sequence of action potentials generated by a neuron), [[2]](#scrollTo=Jq1b4fk6RlWx). Cox processes frequently come up in financial mathematics, especially in areas related to modeling derivatives [[3]](#scrollTo=Jq1b4fk6RlWx) and other credit securities [[4]](#scrollTo=Jq1b4fk6RlWx)."
      ]
    },
    {
      "metadata": {
        "id": "Jq1b4fk6RlWx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "[1] Cox, David R. [\"Some statistical methods connected with series of events.\"](https://www.jstor.org/stable/2983950) Journal of the Royal Statistical Society. Series B (Methodological) (1955): 129-164.  \n",
        "\n",
        "[2] Krumin, Michael, and Shy Shoham. [\"Generation of spike trains with controlled auto-and cross-correlation functions.\"](https://www.mitpressjournals.org/doi/abs/10.1162/neco.2009.08-08-847) Neural Computation 21.6 (2009): 1642-1664.\n",
        "\n",
        "[3] Dassios, Angelos, and Ji-Wook Jang. [\"Pricing of catastrophe reinsurance and derivatives using the Cox process with shot noise intensity.\"](https://link.springer.com/article/10.1007/s007800200079) Finance and Stochastics 7.1 (2003): 73-95.\n",
        "\n",
        "[4] Lando, David. [\"On Cox processes and credit risky securities.\"](https://link.springer.com/article/10.1007/BF01531332) Review of Derivatives research 2.2-3 (1998): 99-120.\n"
      ]
    }
  ]
}