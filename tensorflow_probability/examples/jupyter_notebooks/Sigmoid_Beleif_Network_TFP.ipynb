{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sigmoid_Beleif_Network_TFP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "AxDfcPsLtXVc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "Cs7i1ZEUtXsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XPFoRUIPRTaD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sigmoid Beleif Network with TFP\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/deep_exponential_family_with_tfp.ipynb\"><img height=\"32px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/deep_exponential_family_with_tfp.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Original content [this Repository](https://github.com/blei-lab/edward/blob/master/examples/sigmoid_belief_network.py), created by [the Blei Lab](http://www.cs.columbia.edu/~blei/)\n",
        "\n",
        "Ported to [Tensorflow Probability](https://www.tensorflow.org/probability/) by Matthew McAteer ([`@MatthewMcAteer0`](https://twitter.com/MatthewMcAteer0)), with help from Bryan Seybold, Mike Shwe ([`@mikeshwe`](https://twitter.com/mikeshwe)), Josh Dillon, and the rest of the TFP team at  Google ([`tfprobability@tensorflow.org`](mailto:tfprobability@tensorflow.org)).\n",
        "\n",
        "---\n",
        "\n",
        "- Dependencies & Prerequisites\n",
        "- Introduction\n",
        "  - Data\n",
        "  - Model\n",
        "  - Inference\n",
        "- References"
      ]
    },
    {
      "metadata": {
        "id": "jEui6GrPbbdz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dependencies & Prerequisites\n",
        "\n",
        "<div class=\"alert alert-success\">\n",
        "    Tensorflow Probability is part of the colab default runtime, <b>so you don't need to install Tensorflow or Tensorflow Probability if you're running this in the colab</b>. \n",
        "    <br>\n",
        "    If you're running this notebook in Jupyter on your own machine (and you have already installed Tensorflow), you can use the following\n",
        "    <br>\n",
        "      <ul>\n",
        "    <li> For the most recent nightly installation: <code>pip3 install -q tfp-nightly</code></li>\n",
        "    <li> For the most recent stable TFP release: <code>pip3 install -q --upgrade tensorflow-probability</code></li>\n",
        "    <li> For the most recent stable GPU-connected version of TFP: <code>pip3 install -q --upgrade tensorflow-probability-gpu</code></li>\n",
        "    <li> For the most recent nightly GPU-connected version of TFP: <code>pip3 install -q tfp-nightly-gpu</code></li>\n",
        "    </ul>\n",
        "Again, if you are running this in a Colab, Tensorflow and TFP are already installed\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "MelbdC_ktc_H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Imports and Global Variables  { display-mode: \"form\" }\n",
        "!pip3 install -q observations\n",
        "!pip3 install -q imageio\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)\n",
        "warning_status = \"ignore\" #@param [\"ignore\", \"always\", \"module\", \"once\", \"default\", \"error\"]\n",
        "import warnings\n",
        "warnings.filterwarnings(warning_status)\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(warning_status, category=DeprecationWarning)\n",
        "    warnings.filterwarnings(warning_status, category=UserWarning)\n",
        "\n",
        "import six\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import string\n",
        "from datetime import datetime\n",
        "import os\n",
        "#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/))\n",
        "matplotlib_style = 'fivethirtyeight' #@param ['fivethirtyeight', 'bmh', 'ggplot', 'seaborn', 'default', 'Solarize_Light2', 'classic', 'dark_background', 'seaborn-colorblind', 'seaborn-notebook']\n",
        "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
        "import matplotlib.axes as axes;\n",
        "from matplotlib.patches import Ellipse\n",
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set_context('notebook')\n",
        "from IPython.core.pylabtools import figsize\n",
        "#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)\n",
        "notebook_screen_res = 'retina' #@param ['retina', 'png', 'jpeg', 'svg', 'pdf']\n",
        "%config InlineBackend.figure_format = notebook_screen_res\n",
        "\n",
        "import tensorflow as tf\n",
        "tfe = tf.contrib.eager\n",
        "\n",
        "# Eager Execution\n",
        "\n",
        "#@markdown Check the box below if you want to use [Eager Execution](https://www.tensorflow.org/guide/eager)\n",
        "#@markdown Eager execution provides An intuitive interface, Easier debugging, and a control flow comparable to Numpy. You can read more about it on the [Google AI Blog](https://ai.googleblog.com/2017/10/eager-execution-imperative-define-by.html)\n",
        "use_tf_eager = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Use try/except so we can easily re-execute the whole notebook.\n",
        "if use_tf_eager:\n",
        "    try:\n",
        "        tf.enable_eager_execution()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "\n",
        "  \n",
        "def evaluate(tensors):\n",
        "    \"\"\"Evaluates Tensor or EagerTensor to Numpy `ndarray`s.\n",
        "    Args:\n",
        "    tensors: Object of `Tensor` or EagerTensor`s; can be `list`, `tuple`,\n",
        "      `namedtuple` or combinations thereof.\n",
        "\n",
        "    Returns:\n",
        "      ndarrays: Object with same structure as `tensors` except with `Tensor` or\n",
        "        `EagerTensor`s replaced by Numpy `ndarray`s.\n",
        "    \"\"\"\n",
        "    if tf.executing_eagerly():\n",
        "        return tf.contrib.framework.nest.pack_sequence_as(\n",
        "            tensors,\n",
        "            [t.numpy() if tf.contrib.framework.is_tensor(t) else t\n",
        "             for t in tf.contrib.framework.nest.flatten(tensors)])\n",
        "    return sess.run(tensors)\n",
        "\n",
        "class _TFColor(object):\n",
        "    \"\"\"Enum of colors used in TF docs.\"\"\"\n",
        "    red = '#F15854'\n",
        "    blue = '#5DA5DA'\n",
        "    orange = '#FAA43A'\n",
        "    green = '#60BD68'\n",
        "    pink = '#F17CB0'\n",
        "    brown = '#B2912F'\n",
        "    purple = '#B276B2'\n",
        "    yellow = '#DECF3F'\n",
        "    gray = '#4D4D4D'\n",
        "    def __getitem__(self, i):\n",
        "        return [\n",
        "            self.red,\n",
        "            self.orange,\n",
        "            self.green,\n",
        "            self.blue,\n",
        "            self.pink,\n",
        "            self.brown,\n",
        "            self.purple,\n",
        "            self.yellow,\n",
        "            self.gray,\n",
        "        ][i % 9]\n",
        "TFColor = _TFColor()\n",
        "\n",
        "def session_options(enable_gpu_ram_resizing=True, enable_xla=True):\n",
        "    \"\"\"\n",
        "    Allowing the notebook to make use of GPUs if they're available.\n",
        "    \n",
        "    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear \n",
        "    algebra that optimizes TensorFlow computations.\n",
        "    \"\"\"\n",
        "    config = tf.ConfigProto()\n",
        "    config.log_device_placement = True\n",
        "    if enable_gpu_ram_resizing:\n",
        "        # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
        "        # GPU. Otherwise the colab malloc's all GPU ram.\n",
        "        config.gpu_options.allow_growth = True\n",
        "    if enable_xla:\n",
        "        # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
        "        config.graph_options.optimizer_options.global_jit_level = (\n",
        "            tf.OptimizerOptions.ON_1)\n",
        "    return config\n",
        "\n",
        "\n",
        "def reset_sess(config=None):\n",
        "    \"\"\"\n",
        "    Convenience function to create the TF graph & session or reset them.\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = session_options()\n",
        "    global sess\n",
        "    tf.reset_default_graph()\n",
        "    try:\n",
        "        sess.close()\n",
        "    except:\n",
        "        pass\n",
        "    sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "\n",
        "\n",
        "reset_sess()\n",
        "\n",
        "# from edward.models import Bernoulli\n",
        "from observations import caltech101_silhouettes\n",
        "from scipy.misc import imsave # imsave is deprecated! imsave is deprecated in SciPy 1.0.0, and will be removed in 1.2.0. Use imageio.imwrite instead.\n",
        "\n",
        "class Progbar(object):\n",
        "    def __init__(self, target, width=30, interval=0.01, verbose=1):\n",
        "        \"\"\"(Yet another) progress bar.\n",
        "        Args:\n",
        "          target: int.\n",
        "            Total number of steps expected.\n",
        "          width: int.\n",
        "            Width of progress bar.\n",
        "          interval: float.\n",
        "            Minimum time (in seconds) for progress bar to be displayed\n",
        "            during updates.\n",
        "          verbose: int.\n",
        "            Level of verbosity. 0 suppresses output; 1 is default.\n",
        "        \"\"\"\n",
        "        self.target = target\n",
        "        self.width = width\n",
        "        self.interval = interval\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.stored_values = {}\n",
        "        self.start = time.time()\n",
        "        self.last_update = 0\n",
        "        self.total_width = 0\n",
        "        self.seen_so_far = 0\n",
        "\n",
        "    def update(self, current, values=None, force=False):\n",
        "        \"\"\"Update progress bar, and print to standard output if `force`\n",
        "        is True, or the last update was completed longer than `interval`\n",
        "        amount of time ago, or `current` >= `target`.\n",
        "        The written output is the progress bar and all unique values.\n",
        "        Args:\n",
        "          current: int.\n",
        "            Index of current step.\n",
        "          values: dict of str to float.\n",
        "            Dict of name by value-for-last-step. The progress bar\n",
        "            will display averages for these values.\n",
        "          force: bool.\n",
        "            Whether to force visual progress update.\n",
        "        \"\"\"\n",
        "        if values is None:\n",
        "            values = {}\n",
        "\n",
        "        for k, v in six.iteritems(values):\n",
        "            self.stored_values[k] = v\n",
        "\n",
        "        self.seen_so_far = current\n",
        "\n",
        "        now = time.time()\n",
        "        if (not force and\n",
        "                (now - self.last_update) < self.interval and\n",
        "                current < self.target):\n",
        "            return\n",
        "\n",
        "        self.last_update = now\n",
        "        if self.verbose == 0:\n",
        "            return\n",
        "\n",
        "        prev_total_width = self.total_width\n",
        "        sys.stdout.write(\"\\b\" * prev_total_width)\n",
        "        sys.stdout.write(\"\\r\")\n",
        "\n",
        "        # Write progress bar to stdout.\n",
        "        n_digits = len(str(self.target))\n",
        "        bar = '%%%dd/%%%dd' % (n_digits, n_digits) % (current, self.target)\n",
        "        bar += ' [{0}%]'.format(str(int(current / self.target * 100)).rjust(3))\n",
        "        bar += ' '\n",
        "        prog_width = int(self.width * float(current) / self.target)\n",
        "        if prog_width > 0:\n",
        "            try:\n",
        "                bar += ('â–ˆ' * prog_width)\n",
        "            except UnicodeEncodeError:\n",
        "                bar += ('*' * prog_width)\n",
        "\n",
        "        bar += (' ' * (self.width - prog_width))\n",
        "        sys.stdout.write(bar)\n",
        "\n",
        "        # Write values to stdout.\n",
        "        if current:\n",
        "            time_per_unit = (now - self.start) / current\n",
        "        else:\n",
        "            time_per_unit = 0\n",
        "\n",
        "        eta = time_per_unit * (self.target - current)\n",
        "        info = ''\n",
        "        if current < self.target:\n",
        "            info += ' ETA: %ds' % eta\n",
        "        else:\n",
        "            info += ' Elapsed: %ds' % (now - self.start)\n",
        "\n",
        "        for k, v in six.iteritems(self.stored_values):\n",
        "            info += ' | {0:s}: {1:0.3f}'.format(k, v)\n",
        "\n",
        "        self.total_width = len(bar) + len(info)\n",
        "        if prev_total_width > self.total_width:\n",
        "            info += ((prev_total_width - self.total_width) * \" \")\n",
        "\n",
        "        sys.stdout.write(info)\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        if current >= self.target:\n",
        "            sys.stdout.write(\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IidYCPxqRTaG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "A Sigmoid belief network [1] is a type of deep belief network (DBN). A DBN is a generative graphical model, or alternatively a class of deep neural network, composed of multiple layers of latent variables (\"hidden units\"), with connections between the layers but not between units within each layer.[2]\n",
        "\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Deep_belief_net.svg/440px-Deep_belief_net.svg.png\" width=200>\n",
        "\n",
        "When trained on a set of examples without supervision, a DBN can learn to probabilistically reconstruct its inputs. The layers then act as feature detectors.[2] After this learning step, a DBN can be further trained with supervision to perform classification.[3]\n",
        "\n",
        "For our example, we're going to train our sigmoid belief network on the Caltech 101 Silhouettes data set. First, let's define our model."
      ]
    },
    {
      "metadata": {
        "id": "TrGOjFE_RTaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Hyperparameters\n",
        "data_dir = \"/tmp/data\"\n",
        "out_dir = \"/tmp/out\"\n",
        "#@markdown Batch size during training\n",
        "batch_size = 24                   #@param\n",
        "#@markdown Hidden size per layer from bottom-up\n",
        "hidden_sizes = [300, 100, 50, 10] #@param\n",
        "#@markdown Number of samples for training\n",
        "n_train_samples = 10              #@param\n",
        "#@markdown Number of samples to calculate test log-lik\n",
        "n_test_samples = 1000             #@param\n",
        "#@markdown Learning rate step size\n",
        "step_size = 1e-3                  #@param\n",
        "n_epoch = 100                     #@param\n",
        "n_iter_per_epoch = 10000          #@param\n",
        "\n",
        "if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyvbD5BzRTaQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator(array, batch_size):\n",
        "    \"\"\"\n",
        "    Generate batch with respect to array's first axis.\n",
        "    \"\"\"\n",
        "    start = 0  # pointer to where we are in iteration\n",
        "    while True:\n",
        "        stop = start + batch_size\n",
        "        diff = stop - array.shape[0]\n",
        "        if diff <= 0:\n",
        "            batch = array[start:stop]\n",
        "            start += batch_size\n",
        "        else:\n",
        "            batch = np.concatenate((array[start:], array[:diff]))\n",
        "            start = diff\n",
        "        yield batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VCsJoEnsRTaX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "\n",
        "The Caltech 101 dataset is a dataset of silhouettes for training classifiers. It is a series of black-and-white images that serve as the silhouettes of objects to be classified.\n",
        "\n",
        "<img src=\"https://people.cs.umass.edu/~marlin/data/caltech101s.png\">"
      ]
    },
    {
      "metadata": {
        "id": "7uQNrShaRTaY",
        "colab_type": "code",
        "outputId": "b10d3f4a-92af-4cc8-d65a-370fd73873c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "# Set seed. Remove this line to generate different mixtures!\n",
        "tf.set_random_seed(77)\n",
        "\n",
        "(x_train, _), (x_test, _), (x_valid, _) = caltech101_silhouettes(\n",
        "      data_dir)\n",
        "x_train_generator = generator(x_train, batch_size)\n",
        "x_ph = tf.placeholder(tf.int32, [None, 28 * 28])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Downloading /tmp/data/caltech101_silhouettes_28_split1.mat.part \n",
            ">> [851.7 KB/851.7 KB] 120% @1.2 MB/s,[0s remaining, 0s elapsed]        \n",
            "URL http://people.cs.umass.edu/~marlin/data/caltech101_silhouettes_28_split1.mat downloaded to /tmp/data/caltech101_silhouettes_28_split1.mat \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/observations/util.py:601: ResourceWarning: unclosed <socket.socket fd=59, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.28.0.2', 47886), raddr=('128.119.240.99', 80)>\n",
            "  download_file(url, filepath, hash_true, resume)\n",
            "/usr/local/lib/python3.6/dist-packages/observations/util.py:601: ResourceWarning: unclosed <ssl.SSLSocket fd=60, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.28.0.2', 39926), raddr=('128.119.240.99', 443)>\n",
            "  download_file(url, filepath, hash_true, resume)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "CkglAhNSRTac",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model"
      ]
    },
    {
      "metadata": {
        "id": "q3UlmxDrRTae",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zs = [0] * len(hidden_sizes)\n",
        "for l in reversed(range(len(hidden_sizes))):\n",
        "    if l == len(hidden_sizes) - 1:\n",
        "          logits = tf.zeros([tf.shape(x_ph)[0], hidden_sizes[l]])\n",
        "    else:\n",
        "          logits = tf.layers.dense(tf.cast(zs[l + 1].sample(), tf.float32),\n",
        "                               hidden_sizes[l], activation=None)\n",
        "    zs[l] = tfd.Bernoulli(logits=logits)\n",
        "\n",
        "x = tfd.Bernoulli(logits=tf.layers.dense(tf.cast(zs[0].sample(), tf.float32),\n",
        "                                       28 * 28, activation=None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFOvbezRKNEg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We define the variational model with reverse ordering as probability model. \n",
        "For example: if the layers of $p$ are $15-100-300$ from top-down, then the layers of $q$ are $300-100-15$ from bottom-up."
      ]
    },
    {
      "metadata": {
        "id": "jlPg9ckVK_fR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "qzs = [0] * len(hidden_sizes)\n",
        "for l in range(len(hidden_sizes)):\n",
        "    if l == 0:\n",
        "          logits = tf.layers.dense(tf.cast(x_ph, tf.float32),\n",
        "                               hidden_sizes[l], activation=None)\n",
        "    else:\n",
        "          logits = tf.layers.dense(tf.cast(qzs[l - 1].sample(), tf.float32),\n",
        "                               hidden_sizes[l], activation=None)\n",
        "    qzs[l] = tfd.Bernoulli(logits=logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2o0Ynak2RTai",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ]
    },
    {
      "metadata": {
        "id": "oUBo_FNERTai",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = x.log_prob(x_ph)\n",
        "for z, qz in zip(zs, qzs):\n",
        "    loss += tf.reduce_sum(z.log_prob(qz.sample(sample_shape=n_train_samples)))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=step_size)\n",
        "train_op = optimizer.minimize(loss)\n",
        "\n",
        "tf.global_variables_initializer().run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4etuen9vRTam",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epoch):\n",
        "    print(\"Epoch {}\".format(epoch))\n",
        "    train_loss = 0.0\n",
        "\n",
        "    pbar = Progbar(n_iter_per_epoch)\n",
        "    for t in range(1, n_iter_per_epoch + 1):\n",
        "        pbar.update(t)\n",
        "        x_batch = next(x_train_generator)\n",
        "        [_, loss_] = sess.run([train_op, loss], feed_dict={x_ph: x_batch})\n",
        "        train_loss += loss\n",
        "\n",
        "    # Print per-data point loss, averaged over training epoch.\n",
        "    train_loss /= n_iter_per_epoch\n",
        "    train_loss /= batch_size\n",
        "    print(\"Training negative log-likelihood: {:0.3f}\".format(train_loss))\n",
        "\n",
        "    # Prior predictive check.\n",
        "    images = sess.run(x, {x_ph: x_batch})  # feed ph to determine sample size\n",
        "    for m in range(batch_size):\n",
        "        imsave(\"{}/{}.png\".format(out_dir, m), images[m].reshape(28, 28))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MgoYxykBwxLB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "Default settings take ~143s / epoch on a Titan X (Pascal). \n",
        "\n",
        "Results on epoch 100:\n",
        "- Training negative log-likelihood: 209.443\n",
        "- Test negative log-likelihood: 161.244\n",
        "- Using n_train_samples=50 converges to test NLL of 157.824."
      ]
    },
    {
      "metadata": {
        "id": "2rGFv5Y2RTap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "\n",
        "[1] [Sigmoid belief network (Neal, 1990)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.1777&rep=rep1&type=pdf)\n",
        "\n",
        "[2] Hinton, Geoffrey E. [\"Deep belief networks.\"](http://www.scholarpedia.org/article/Deep_belief_networks) Scholarpedia 4.5 (2009): 5947.\n",
        "\n",
        "[3] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. [\"A fast learning algorithm for deep belief nets.\"](http://www.cs.toronto.edu/~hinton/absps/fastnc.pdf) Neural computation 18.7 (2006): 1527-1554.\n",
        "\n",
        "Additional Sources Reading:\n",
        "- [Mean Field Theory for Sigmoid Belief Networks](https://arxiv.org/pdf/cs/9603102.pdf)\n",
        "- [Learning Deep Sigmoid Belief Networks with Data Augmentation](http://people.ee.duke.edu/~lcarin/dsbn_aistats2015.pdf)\n",
        "- [Learning Sigmoid Belief Networks via Monte Carlo Expectation Maximization](http://proceedings.mlr.press/v51/song16.html)\n",
        "- [Learning Deep Sigmoid Belief Networks with Data Augmentation](http://proceedings.mlr.press/v38/gan15.html)\n",
        "- [Incremental Sigmoid Belief Networks for Grammar Learning](http://www.jmlr.org/papers/volume11/henderson10a/henderson10a.pdf)"
      ]
    },
    {
      "metadata": {
        "id": "3MHuERH0RTap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "def css_styling():\n",
        "    styles = open(\"../styles/custom.css\", \"r\").read()\n",
        "    return HTML(styles)\n",
        "css_styling()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}