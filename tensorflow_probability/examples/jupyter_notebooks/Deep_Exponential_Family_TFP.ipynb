{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Exponential_Family_TFP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "X8rXpneSaAsU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "oXEdGST4aAfX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ECsuwM84RHHm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Exponential Family with TFP\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/deep_exponential_family_with_tfp.ipynb\"><img height=\"32px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/deep_exponential_family_with_tfp.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "Original content [this Repository](https://github.com/blei-lab/edward/blob/master/examples/deep_exponential_family.py) and [this paper](http://www.cs.toronto.edu/~lcharlin/papers/def_aistats.pdf), created by [the Blei Lab](http://www.cs.columbia.edu/~blei/)\n",
        "\n",
        "Ported to [Tensorflow Probability](https://www.tensorflow.org/probability/) by Matthew McAteer ([`@MatthewMcAteer0`](https://twitter.com/MatthewMcAteer0)), with help from Bryan Seybold, Mike Shwe ([`@mikeshwe`](https://twitter.com/mikeshwe)), Josh Dillon, and the rest of the TFP team at  Google ([`tfprobability@tensorflow.org`](mailto:tfprobability@tensorflow.org)).\n",
        "\n",
        "---\n",
        "\n",
        "- Dependencies & Prerequisites\n",
        "- Introduction\n",
        "- Our example\n",
        "  - Hyperparameters\n",
        "  - Data\n",
        "  - Model\n",
        "  - Inference\n",
        "- References"
      ]
    },
    {
      "metadata": {
        "id": "YJF4CVOaXeMT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dependencies & Prerequisites\n",
        "\n",
        "<div class=\"alert alert-success\">\n",
        "    Tensorflow Probability is part of the colab default runtime, <b>so you don't need to install Tensorflow or Tensorflow Probability if you're running this in the colab</b>. \n",
        "    <br>\n",
        "    If you're running this notebook in Jupyter on your own machine (and you have already installed Tensorflow), you can use the following\n",
        "    <br>\n",
        "      <ul>\n",
        "    <li> For the most recent nightly installation: <code>pip3 install -q tfp-nightly</code></li>\n",
        "    <li> For the most recent stable TFP release: <code>pip3 install -q --upgrade tensorflow-probability</code></li>\n",
        "    <li> For the most recent stable GPU-connected version of TFP: <code>pip3 install -q --upgrade tensorflow-probability-gpu</code></li>\n",
        "    <li> For the most recent nightly GPU-connected version of TFP: <code>pip3 install -q tfp-nightly-gpu</code></li>\n",
        "    </ul>\n",
        "Again, if you are running this in a Colab, Tensorflow and TFP are already installed\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "Jv-uVD3UXdta",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Imports and Global Variables  { display-mode: \"form\" }\n",
        "!pip3 install -q observations\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)\n",
        "warning_status = \"ignore\" #@param [\"ignore\", \"always\", \"module\", \"once\", \"default\", \"error\"]\n",
        "import warnings\n",
        "warnings.filterwarnings(warning_status)\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(warning_status, category=DeprecationWarning)\n",
        "    warnings.filterwarnings(warning_status, category=UserWarning)\n",
        "\n",
        "from absl import flags\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "from six.moves import urllib\n",
        "import string\n",
        "import time\n",
        "import collections\n",
        "from contextlib import contextmanager\n",
        "\n",
        "#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/))\n",
        "matplotlib_style = 'fivethirtyeight' #@param ['fivethirtyeight', 'bmh', 'ggplot', 'seaborn', 'default', 'Solarize_Light2', 'classic', 'dark_background', 'seaborn-colorblind', 'seaborn-notebook']\n",
        "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
        "import matplotlib.axes as axes;\n",
        "from matplotlib.patches import Ellipse\n",
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set_context('notebook')\n",
        "from IPython.core.pylabtools import figsize\n",
        "#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)\n",
        "notebook_screen_res = 'retina' #@param ['retina', 'png', 'jpeg', 'svg', 'pdf']\n",
        "%config InlineBackend.figure_format = notebook_screen_res\n",
        "\n",
        "import tensorflow as tf\n",
        "tfe = tf.contrib.eager\n",
        "\n",
        "# Eager Execution\n",
        "#@markdown Check the box below if you want to use [Eager Execution](https://www.tensorflow.org/guide/eager)\n",
        "#@markdown Eager execution provides An intuitive interface, Easier debugging, and a control flow comparable to Numpy. You can read more about it on the [Google AI Blog](https://ai.googleblog.com/2017/10/eager-execution-imperative-define-by.html)\n",
        "use_tf_eager = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Use try/except so we can easily re-execute the whole notebook.\n",
        "if use_tf_eager:\n",
        "    try:\n",
        "        tf.enable_eager_execution()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "from tensorflow_probability import edward2 as ed\n",
        "  \n",
        "def evaluate(tensors):\n",
        "    \"\"\"Evaluates Tensor or EagerTensor to Numpy `ndarray`s.\n",
        "    Args:\n",
        "    tensors: Object of `Tensor` or EagerTensor`s; can be `list`, `tuple`,\n",
        "      `namedtuple` or combinations thereof.\n",
        "\n",
        "    Returns:\n",
        "      ndarrays: Object with same structure as `tensors` except with `Tensor` or\n",
        "        `EagerTensor`s replaced by Numpy `ndarray`s.\n",
        "    \"\"\"\n",
        "    if tf.executing_eagerly():\n",
        "        return tf.contrib.framework.nest.pack_sequence_as(\n",
        "            tensors,\n",
        "            [t.numpy() if tf.contrib.framework.is_tensor(t) else t\n",
        "             for t in tf.contrib.framework.nest.flatten(tensors)])\n",
        "    return sess.run(tensors)\n",
        "\n",
        "class _TFColor(object):\n",
        "    \"\"\"Enum of colors used in TF docs.\"\"\"\n",
        "    red = '#F15854'\n",
        "    blue = '#5DA5DA'\n",
        "    orange = '#FAA43A'\n",
        "    green = '#60BD68'\n",
        "    pink = '#F17CB0'\n",
        "    brown = '#B2912F'\n",
        "    purple = '#B276B2'\n",
        "    yellow = '#DECF3F'\n",
        "    gray = '#4D4D4D'\n",
        "    def __getitem__(self, i):\n",
        "        return [\n",
        "            self.red,\n",
        "            self.orange,\n",
        "            self.green,\n",
        "            self.blue,\n",
        "            self.pink,\n",
        "            self.brown,\n",
        "            self.purple,\n",
        "            self.yellow,\n",
        "            self.gray,\n",
        "        ][i % 9]\n",
        "TFColor = _TFColor()\n",
        "\n",
        "def session_options(enable_gpu_ram_resizing=True, enable_xla=True):\n",
        "    \"\"\"\n",
        "    Allowing the notebook to make use of GPUs if they're available.\n",
        "    \n",
        "    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear \n",
        "    algebra that optimizes TensorFlow computations.\n",
        "    \"\"\"\n",
        "    config = tf.ConfigProto()\n",
        "    config.log_device_placement = True\n",
        "    if enable_gpu_ram_resizing:\n",
        "        # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
        "        # GPU. Otherwise the colab malloc's all GPU ram.\n",
        "        config.gpu_options.allow_growth = True\n",
        "    if enable_xla:\n",
        "        # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
        "        config.graph_options.optimizer_options.global_jit_level = (\n",
        "            tf.OptimizerOptions.ON_1)\n",
        "    return config\n",
        "\n",
        "\n",
        "def reset_sess(config=None):\n",
        "    \"\"\"\n",
        "    Convenience function to create the TF graph & session or reset them.\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = session_options()\n",
        "    global sess\n",
        "    tf.reset_default_graph()\n",
        "    try:\n",
        "        sess.close()\n",
        "    except:\n",
        "        pass\n",
        "    sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "reset_sess()\n",
        "\n",
        "# from edward.models import Gamma, Poisson, Normal, PointMass, TransformedDistribution\n",
        "# from edward.util import Progbar\n",
        "from observations import nips\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fYTUqdHKXipl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook demonstrates how to use a Sparse Gamma deep exponential family like the kind described in [Ranganath et al., 2015](http://proceedings.mlr.press/v38/ranganath15.pdf).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "pr6yQg-eRHHo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Our example\n",
        "\n",
        "We apply it as a topic model on the collection of NIPS 2011 conference papers."
      ]
    },
    {
      "metadata": {
        "id": "sGdZDAPiB0Ei",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Hyperparameters\n",
        "\n",
        "#@markdown Initial learning rate (default=`1e-4`)\n",
        "learning_rate = 0.001 #@param  {type:\"number\", allow-input: true}\n",
        "#@markdown Number of training steps to run (default=`200000`)\n",
        "max_steps = 200000 #@param {type:\"slider\", min:10000, max:200000, step:1000}\n",
        "#@markdown Comma-separated list denoting number of latent variables (stochastic units) per layer. (default=[`\"100\"`, `\"30\"`, `\"15\"`])\n",
        "layer_sizes = [\"100\", \"30\", \"15\"] #@param {type:\"raw\"}\n",
        "#@markdown Shape hyperparameter for Gamma priors on latents. (default=0.1)\n",
        "shape = 0.1 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
        "#@markdown Directory where data is stored (if using real data).\n",
        "data_dir = os.path.join(os.getenv(\"TEST_TMPDIR\", \"/tmp\"), \"deep_exponential_family/data\") #@param {type:\"raw\"}\n",
        "#@markdown Directory to put the model's fit.\n",
        "model_dir = os.path.join(os.getenv(\"TEST_TMPDIR\", \"/tmp\"), \"deep_exponential_family/\")#@param {type:\"raw\"}\n",
        "#@markdown If true, uses fake data. Defaults to real data (default=None)\n",
        "fake_data = None #@param [None, True] {type:\"raw\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HfDHMZVcRHHz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "Our Model is a multi-layered topic model over a documents-by-terms matrix. We can picture it as a combination of the following nested model (based on the Gamma distribution shape parameter $k$ being provided):\n",
        "$$\n",
        "\\textbf{Z}_2 = \\text{Gamma}(\\text{shape}=0.1\\text{, scale}=0.1) \\\\\n",
        "\\textbf{W}_2 = \\text{Gamma}(\\text{shape}=0.1, \\text{scale}=0.3) \\\\\n",
        "\\textbf{Z}_1 = \\text{Gamma}(\\text{shape}=k\\text{,  scale}=k/(\\textbf{Z}_2\\textbf{W}_2^T)) \\\\\n",
        "\\textbf{W}_1 = \\text{Gamma}(\\text{shape}=0.1, \\text{scale}=0.3) \\\\\n",
        "\\textbf{Z}_0 = \\text{Gamma}(\\text{shape}=k\\text{,  scale}=k/(\\textbf{Z}_1\\textbf{W}_1^T)) \\\\\n",
        "\\textbf{W}_0 = \\text{Gamma}(\\text{shape}=0.1, \\text{scale}=0.3) \\\\\n",
        "\\text{ }\\\\\n",
        "x = \\text{Poisson}(\\textbf{Z}_0\\textbf{W}_0^T) \n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "zrXhfjr8RHHz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deep_exponential_family(data_size, feature_size, units, shape):\n",
        "    \"\"\"A multi-layered topic model over a documents-by-terms matrix.\"\"\"\n",
        "    w2 = tfd.Gamma(tf.fill([units[2], units[1]], 0.1), tf.fill([units[2], units[1]], 0.3), name=\"w2\")\n",
        "    w1 = tfd.Gamma(tf.fill([units[1], units[0]], 0.1), tf.fill([units[1], units[0]], 0.3), name=\"w1\")\n",
        "    w0 = tfd.Gamma(tf.fill([units[0], feature_size], 0.1), tf.fill([units[0], feature_size], 0.3), name=\"w0\")\n",
        "\n",
        "    z2 = tfd.Gamma(tf.fill([data_size, units[2]], 0.1), tf.fill([data_size, units[2]], 0.1), name=\"z2\")\n",
        "    z1 = tfd.Gamma(shape, shape / tf.matmul(z2.sample(), w2.sample()), name=\"z1\")\n",
        "    z0 = tfd.Gamma(shape, shape / tf.matmul(z1.sample(), w1.sample()), name=\"z0\")\n",
        "    x = tfd.Poisson(tf.matmul(z0.sample(), w0.sample()), name=\"x\")\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FF1TvorGnbpP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first of these is our learnable deterministic distribution over positive reals."
      ]
    },
    {
      "metadata": {
        "id": "S3ubbvHGCDrF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainable_positive_deterministic(shape, min_loc=1e-3, name=None):\n",
        "    \"\"\"Learnable Deterministic distribution over positive reals.\"\"\"\n",
        "    with tf.variable_scope(None, default_name=\"trainable_positive_deterministic\"):\n",
        "        unconstrained_loc = tf.get_variable(\"unconstrained_loc\", shape)\n",
        "        loc = tf.maximum(tf.nn.softplus(unconstrained_loc), min_loc)\n",
        "        rv = tfd.Deterministic(loc=loc, name=name)\n",
        "        return rv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d-W1oPqnndUG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next up we have the learnable gamma distribution ($\\text{Gamma}(\\alpha, \\beta)$) via concentration and scale parameterization. We have a gamma distribution. "
      ]
    },
    {
      "metadata": {
        "id": "pv6-PWqfCMDl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainable_gamma(shape, min_concentration=1e-3, min_scale=1e-5, name=None):\n",
        "    \"\"\"Learnable Gamma via concentration and scale parameterization.\"\"\"\n",
        "    with tf.variable_scope(None, default_name=\"trainable_gamma\"):\n",
        "        unconstrained_concentration = tf.get_variable(\n",
        "            \"unconstrained_concentration\", shape,\n",
        "            initializer=tf.random_normal_initializer(mean=0.5, stddev=0.1))\n",
        "        unconstrained_scale = tf.get_variable(\n",
        "            \"unconstrained_scale\", shape,\n",
        "            initializer=tf.random_normal_initializer(stddev=0.1))\n",
        "        concentration = tf.maximum(tf.nn.softplus(unconstrained_concentration),\n",
        "                                   min_concentration)\n",
        "        rate = tf.maximum(1. / tf.nn.softplus(unconstrained_scale), 1. / min_scale)\n",
        "        rv = tfd.Gamma(concentration=concentration, rate=rate, name=name)\n",
        "        return rv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oc6BsB_VmZwY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can define the Posterior approximation for deep exponential family, which we can define as follows:\n",
        "$$p(w_{0,1,2}, z_{1,2,3} | x)$$"
      ]
    },
    {
      "metadata": {
        "id": "vkQ4p8LyCQk6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deep_exponential_family_variational(data_size, feature_size, units):\n",
        "    \"\"\"Posterior approx. for deep exponential family p(w{0,1,2}, z{1,2,3} | x).\"\"\"\n",
        "    qw2 = trainable_positive_deterministic([units[2], units[1]], name=\"qw2\")\n",
        "    qw1 = trainable_positive_deterministic([units[1], units[0]], name=\"qw1\")\n",
        "    qw0 = trainable_positive_deterministic([units[0], feature_size], name=\"qw0\")\n",
        "    qz2 = trainable_gamma([data_size, units[2]], name=\"qz2\")\n",
        "    qz1 = trainable_gamma([data_size, units[1]], name=\"qz1\")\n",
        "    qz0 = trainable_gamma([data_size, units[0]], name=\"qz0\")\n",
        "    return qw2, qw1, qw0, qz2, qz1, qz0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CZS2mICgRHHw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "\n",
        "The NIPS 1987-2015 data set is in the form of a $ 11,463 \\times 5,812$ matrix of per-paper word counts, containing $11,463$ words and $5,811$ NIPS conference papers (Perrone et al., 2016). We subset to papers in 2011 and words appearing in at least two documents and having a total word count of at least 10. Built from the Observations Python package."
      ]
    },
    {
      "metadata": {
        "id": "5D1DvivERHHx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_nips2011_papers(path):\n",
        "    \"\"\"Loads NIPS 2011 conference papers.\n",
        "    The NIPS 1987-2015 data set is in the form of a 11,463 x 5,812 matrix of\n",
        "    per-paper word counts, containing 11,463 words and 5,811 NIPS conference\n",
        "    papers (Perrone et al., 2016). We subset to papers in 2011 and words appearing\n",
        "    in at least two documents and having a total word count of at least 10.\n",
        "    Built from the Observations Python package.\n",
        "    Args:\n",
        "        path: str.\n",
        "          Path to directory which either stores file or otherwise file will\n",
        "          be downloaded and extracted there. Filename is `NIPS_1987-2015.csv`.\n",
        "    Returns:\n",
        "        bag_of_words: np.ndarray of shape [num_documents, num_words]. Each element\n",
        "          denotes the number of occurrences of a specific word in a specific\n",
        "          document.\n",
        "        words: List of strings, denoting the words for `bag_of_words`'s columns.\n",
        "    \"\"\"\n",
        "    path = os.path.expanduser(path)\n",
        "    filename = \"NIPS_1987-2015.csv\"\n",
        "    filepath = os.path.join(path, filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        url = (\"https://archive.ics.uci.edu/ml/machine-learning-databases/\"\n",
        "                 \"00371/NIPS_1987-2015.csv\")\n",
        "        if not tf.gfile.Exists(path):\n",
        "            tf.gfile.MakeDirs(path)\n",
        "        print(\"Downloading %s to %s\" % (url, filepath))\n",
        "        urllib.request.urlretrieve(url, filepath)\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        iterator = csv.reader(f)\n",
        "        documents = next(iterator)[1:]\n",
        "        words = []\n",
        "        x_train = []\n",
        "        for row in iterator:\n",
        "            words.append(row[0])\n",
        "            x_train.append(row[1:])\n",
        "\n",
        "    x_train = np.array(x_train, dtype=np.int)\n",
        "\n",
        "    # Subset to documents in 2011 and words appearing in at least two documents\n",
        "    # and have a total word count of at least 10.\n",
        "    doc_idx = [i for i, document in enumerate(documents)\n",
        "               if document.startswith(\"2011\")]\n",
        "    documents = [documents[doc] for doc in doc_idx]\n",
        "    x_train = x_train[:, doc_idx]\n",
        "    word_idx = np.logical_and(np.sum(x_train != 0, 1) >= 2,\n",
        "                              np.sum(x_train, 1) >= 10)\n",
        "    words = [word for word, idx in zip(words, word_idx) if idx]\n",
        "    bag_of_words = x_train[word_idx, :].T\n",
        "    return bag_of_words, words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wWHwWh1jib-6",
        "colab_type": "code",
        "outputId": "e80b86aa-0e7f-4342-92f6-233ff9c7aabe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "layer_sizes = [int(layer_size) for layer_size in layer_sizes]\n",
        "if len(layer_sizes) != 3:\n",
        "    raise NotImplementedError(\"Specifying fewer or more than 3 layers is not \"\n",
        "                              \"currently available.\")\n",
        "if tf.gfile.Exists(model_dir):\n",
        "    tf.logging.warning(\n",
        "        \"Warning: deleting old log directory at {}\".format(model_dir))\n",
        "    tf.gfile.DeleteRecursively(model_dir)\n",
        "tf.gfile.MakeDirs(model_dir)\n",
        "\n",
        "if fake_data:\n",
        "    bag_of_words = np.random.poisson(1., size=[10, 25])\n",
        "    words = [str(i) for i in range(25)]\n",
        "else:\n",
        "    bag_of_words, words = load_nips2011_papers(data_dir)\n",
        "\n",
        "total_count = np.sum(bag_of_words)\n",
        "bag_of_words = tf.to_float(bag_of_words)\n",
        "data_size, feature_size = bag_of_words.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://archive.ics.uci.edu/ml/machine-learning-databases/00371/NIPS_1987-2015.csv to /tmp/deep_exponential_family/data/NIPS_1987-2015.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "79dQqhQDHI9U",
        "colab_type": "code",
        "outputId": "0d7e64d4-464e-411b-ae10-01006b3414cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"total_count: {}\".format(total_count))\n",
        "print(\"bag_of_words: {}\".format(bag_of_words))\n",
        "print(\"data_size: {}\".format(data_size))\n",
        "print(\"feature_size: {}\".format(feature_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_count: 669197\n",
            "bag_of_words: Tensor(\"ToFloat:0\", shape=(305, 5970), dtype=float32)\n",
            "data_size: 305\n",
            "feature_size: 5970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6DI0JGM9RHH0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ]
    },
    {
      "metadata": {
        "id": "mpB3W0NND7e8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compute expected log-likelihood. First, sample from the variational\n",
        "# distribution; second, compute the log-likelihood given the sample.\n",
        "qw2, qw1, qw0, qz2, qz1, qz0 = deep_exponential_family_variational(\n",
        "    data_size,\n",
        "    feature_size,\n",
        "    layer_sizes)\n",
        "\n",
        "posterior_predictive = deep_exponential_family(data_size=data_size, \n",
        "                                               feature_size=feature_size,\n",
        "                                               units=layer_sizes, \n",
        "                                               shape=shape)\n",
        "\n",
        "log_likelihood = posterior_predictive.log_prob(bag_of_words)\n",
        "log_likelihood = tf.reduce_sum(log_likelihood)\n",
        "tf.summary.scalar(\"log_likelihood\", log_likelihood);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lNSpt4PgNfa7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining our prior distributions\n",
        "\n",
        "w2_prior = tfd.Gamma(tf.fill([layer_sizes[2], layer_sizes[1]], 0.1), \n",
        "                     tf.fill([layer_sizes[2], layer_sizes[1]], 0.3), \n",
        "                     name=\"w2_prior\")\n",
        "w1_prior = tfd.Gamma(tf.fill([layer_sizes[1], layer_sizes[0]], 0.1), \n",
        "                     tf.fill([layer_sizes[1], layer_sizes[0]], 0.3), \n",
        "                     name=\"w1_prior\")\n",
        "w0_prior = tfd.Gamma(tf.fill([layer_sizes[0], feature_size], 0.1), \n",
        "                     tf.fill([layer_sizes[0], feature_size], 0.3), \n",
        "                     name=\"w0_prior\")\n",
        "z2_prior = tfd.Gamma(tf.fill([data_size, layer_sizes[2]], 0.1), \n",
        "                     tf.fill([data_size, layer_sizes[2]], 0.1), \n",
        "                     name=\"z2_prior\")\n",
        "z1_prior = tfd.Gamma(shape, \n",
        "                     shape / tf.matmul(z2_prior.sample(), w2_prior.sample()), \n",
        "                     name=\"z1_prior\")\n",
        "z0_prior = tfd.Gamma(shape, \n",
        "                     shape / tf.matmul(z1_prior.sample(), w1_prior.sample()), \n",
        "                     name=\"z0_prior\")\n",
        "\n",
        "# Compute analytic KL-divergence between variational and prior distributions.\n",
        "kl = 0.\n",
        "kl += tf.reduce_sum(qz0.kl_divergence(z0_prior))\n",
        "kl += tf.reduce_sum(qz1.kl_divergence(z1_prior))\n",
        "kl += tf.reduce_sum(qz2.kl_divergence(z2_prior))\n",
        "kl += tf.reduce_sum(qw0.kl_divergence(w0_prior))\n",
        "kl += tf.reduce_sum(qw1.kl_divergence(w1_prior))\n",
        "kl += tf.reduce_sum(qw2.kl_divergence(w2_prior))\n",
        "\n",
        "tf.summary.scalar(\"kl\", kl);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MuWDAFzpO4wI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Log-likelihood and Kullbackâ€“Leibler divergence are then combined into the Evidence Lower BOund (ELBO) loss. We will minimize the ELBO using the Adam Algorithm ([Kingma et al., 2014](https://arxiv.org/abs/1412.6980))."
      ]
    },
    {
      "metadata": {
        "id": "WDxJhffQq0DN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "elbo = log_likelihood - kl\n",
        "tf.summary.scalar(\"elbo\", elbo)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "train_op = optimizer.minimize(-elbo)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CS9s0ntgOOPy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can finally run our inference. \n",
        "\n",
        "**NOTE**: The loss function can sometimes erroneously output a negative value or `NaN`. This happens when the samples from the variational approximation are numerically zero, which causes Gamma log probs to output `inf`."
      ]
    },
    {
      "metadata": {
        "id": "uj8JX-2NRHH2",
        "colab_type": "code",
        "outputId": "fb2c9cef-d311-4c0b-a145-da99cf67085f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9537
        }
      },
      "cell_type": "code",
      "source": [
        "summary = tf.summary.merge_all()\n",
        "summary_writer = tf.summary.FileWriter(model_dir, sess.graph)\n",
        "start_time = time.time()\n",
        "\n",
        "evaluate(tf.global_variables_initializer())\n",
        "for step in range(max_steps):\n",
        "    start_time = time.time()\n",
        "    _, elbo_value = evaluate([train_op, elbo])\n",
        "    if step % 500 == 0:\n",
        "        duration = time.time() - start_time\n",
        "        print(\"Step: {:>3d} Loss: {:.3f} ({:.3f} sec)\".format(\n",
        "              step, elbo_value, duration))\n",
        "        summary_str = evaluate(summary)\n",
        "        summary_writer.add_summary(summary_str, step)\n",
        "        summary_writer.flush()\n",
        "\n",
        "        # Compute perplexity of the full data set. The model's negative\n",
        "        # log-likelihood of data is upper bounded by the variational objective.\n",
        "        negative_log_likelihood = -elbo_value\n",
        "        perplexity = np.exp(negative_log_likelihood / total_count)\n",
        "        print(\"Negative log-likelihood <= {:0.3f}\".format(\n",
        "              negative_log_likelihood))\n",
        "        print(\"Perplexity <= {:0.3f}\".format(perplexity))\n",
        "\n",
        "        # Print top 10 words for first 10 topics.\n",
        "        qw0_values = evaluate(qw0.sample())\n",
        "        for k in range(min(10, layer_sizes[-1])):\n",
        "            top_words_idx = qw0_values[k, :].argsort()[-10:][::-1]\n",
        "            top_words = \" \".join([words[i] for i in top_words_idx])\n",
        "            print(\"Topic {}: {}\".format(k, top_words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step:   0 Loss: -2501358080.000 (0.726 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Negative log-likelihood <= 2501358080.000\n",
            "Perplexity <= inf\n",
            "Topic 0: reward alarm conference advance highlighted projecting similarly sources semantics date\n",
            "Topic 1: write dan optimised advantages category opportunity issues play aggregated tries\n",
            "Topic 2: comprehensive forms cessing valuable ancestors tails critic indexing raises phys\n",
            "Topic 3: shortly black accomplished instead specifies rise invariance lausanne shrink maintain\n",
            "Topic 4: orders saw regressors phrase star observes sapiro impression morgan formal\n",
            "Topic 5: agglomerative together separation tenenbaum cauchy interscience animals environment mild berkeley\n",
            "Topic 6: syst describing tendency completed opposed capable lambda restaurant riding prevalence\n",
            "Topic 7: location segments lemmas static treated connected generative sphere diagnostic contribution\n",
            "Topic 8: speaker darpa refinement schneider shamir adversarial vary altun savings may\n",
            "Topic 9: platform clearly overhead ibp ronald evaluations extensions jacobian typically chapelle\n",
            "Step: 500 Loss: -4907651584.000 (0.196 sec)\n",
            "Negative log-likelihood <= 4907651584.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: reward alarm conference advance highlighted projecting similarly sources semantics date\n",
            "Topic 1: write dan optimised advantages category opportunity issues play aggregated tries\n",
            "Topic 2: comprehensive forms cessing valuable ancestors tails critic indexing raises phys\n",
            "Topic 3: shortly black accomplished instead specifies rise invariance lausanne shrink maintain\n",
            "Topic 4: orders saw regressors phrase star observes sapiro impression morgan formal\n",
            "Topic 5: agglomerative together separation tenenbaum cauchy interscience animals environment mild berkeley\n",
            "Topic 6: syst describing tendency completed opposed capable lambda restaurant riding prevalence\n",
            "Topic 7: location segments lemmas static treated connected generative sphere diagnostic contribution\n",
            "Topic 8: speaker darpa refinement schneider shamir adversarial vary altun savings may\n",
            "Topic 9: platform clearly overhead ibp ronald evaluations extensions jacobian typically chapelle\n",
            "Step: 1000 Loss: -3812073984.000 (0.196 sec)\n",
            "Negative log-likelihood <= 3812073984.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: reward alarm conference advance highlighted projecting similarly sources semantics date\n",
            "Topic 1: write dan optimised advantages category opportunity issues play aggregated tries\n",
            "Topic 2: comprehensive forms cessing valuable ancestors tails critic indexing raises phys\n",
            "Topic 3: shortly black accomplished instead specifies rise invariance lausanne shrink maintain\n",
            "Topic 4: orders saw regressors phrase star observes sapiro impression morgan formal\n",
            "Topic 5: agglomerative together separation tenenbaum cauchy interscience animals environment mild berkeley\n",
            "Topic 6: syst describing tendency completed opposed capable lambda restaurant riding prevalence\n",
            "Topic 7: location segments lemmas static treated connected generative sphere diagnostic contribution\n",
            "Topic 8: speaker darpa refinement schneider shamir adversarial vary altun savings may\n",
            "Topic 9: platform clearly overhead ibp ronald evaluations extensions jacobian typically chapelle\n",
            "Step: 1500 Loss: -2428504320.000 (0.196 sec)\n",
            "Negative log-likelihood <= 2428504320.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: reward alarm conference advance highlighted projecting similarly sources semantics date\n",
            "Topic 1: write dan optimised advantages category opportunity issues play aggregated tries\n",
            "Topic 2: comprehensive forms cessing valuable ancestors tails critic indexing raises phys\n",
            "Topic 3: shortly black accomplished instead specifies rise invariance lausanne shrink maintain\n",
            "Topic 4: orders saw regressors phrase star observes sapiro impression morgan formal\n",
            "Topic 5: agglomerative together separation tenenbaum cauchy interscience animals environment mild berkeley\n",
            "Topic 6: syst describing tendency completed opposed capable lambda restaurant riding prevalence\n",
            "Topic 7: location segments lemmas static treated connected generative sphere diagnostic contribution\n",
            "Topic 8: speaker darpa refinement schneider shamir adversarial vary altun savings may\n",
            "Topic 9: platform clearly overhead ibp ronald evaluations extensions jacobian typically chapelle\n",
            "Step: 2000 Loss: -4161859840.000 (0.193 sec)\n",
            "Negative log-likelihood <= 4161859840.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: reward alarm conference advance highlighted projecting similarly sources semantics date\n",
            "Topic 1: write dan optimised advantages category opportunity issues play aggregated tries\n",
            "Topic 2: comprehensive forms cessing valuable ancestors tails critic indexing raises phys\n",
            "Topic 3: shortly black accomplished instead specifies rise invariance lausanne shrink maintain\n",
            "Topic 4: orders saw regressors phrase star observes sapiro impression morgan formal\n",
            "Topic 5: agglomerative together separation tenenbaum cauchy interscience animals environment mild berkeley\n",
            "Topic 6: syst tendency describing completed opposed capable lambda restaurant riding prevalence\n",
            "Topic 7: location segments lemmas static treated connected generative sphere diagnostic contribution\n",
            "Topic 8: speaker darpa refinement schneider shamir adversarial vary altun savings may\n",
            "Topic 9: platform clearly overhead ibp ronald evaluations extensions jacobian typically chapelle\n",
            "Step: 2500 Loss: -3855008512.000 (0.194 sec)\n",
            "Negative log-likelihood <= 3855008512.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: reward alarm conference advance highlighted projecting similarly sources semantics date\n",
            "Topic 1: write dan optimised advantages category opportunity issues play aggregated tries\n",
            "Topic 2: comprehensive forms cessing valuable ancestors tails critic indexing raises phys\n",
            "Topic 3: shortly black accomplished instead specifies rise invariance shrink lausanne maintain\n",
            "Topic 4: orders saw regressors phrase star observes sapiro impression morgan formal\n",
            "Topic 5: agglomerative together separation tenenbaum cauchy interscience animals environment mild berkeley\n",
            "Topic 6: syst describing tendency completed opposed capable lambda restaurant riding prevalence\n",
            "Topic 7: location segments lemmas static treated connected generative diagnostic sphere contribution\n",
            "Topic 8: speaker darpa refinement schneider shamir adversarial vary altun may savings\n",
            "Topic 9: platform clearly overhead ibp ronald evaluations extensions jacobian typically chapelle\n",
            "Step: 3000 Loss: -2587465216.000 (0.196 sec)\n",
            "Negative log-likelihood <= 2587465216.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: reward alarm conference advance highlighted similarly projecting sources semantics date\n",
            "Topic 1: write dan optimised advantages category opportunity issues play aggregated tries\n",
            "Topic 2: comprehensive forms cessing valuable ancestors tails critic indexing raises parametric\n",
            "Topic 3: shortly accomplished black instead specifies rise invariance shrink lausanne maintain\n",
            "Topic 4: orders saw regressors phrase star observes sapiro impression morgan formal\n",
            "Topic 5: agglomerative together separation tenenbaum cauchy interscience environment animals mild berkeley\n",
            "Topic 6: syst tendency describing completed opposed capable lambda restaurant riding prevalence\n",
            "Topic 7: location segments lemmas static treated connected generative sphere diagnostic contribution\n",
            "Topic 8: speaker darpa refinement schneider shamir adversarial vary altun may savings\n",
            "Topic 9: overhead platform clearly ibp ronald evaluations extensions jacobian typically chapelle\n",
            "Step: 3500 Loss: -2203924992.000 (0.202 sec)\n",
            "Negative log-likelihood <= 2203924992.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: reward alarm advance conference highlighted similarly projecting sources semantics date\n",
            "Topic 1: write dan optimised advantages category opportunity issues play aggregated tries\n",
            "Topic 2: comprehensive forms cessing valuable ancestors tails critic indexing raises phys\n",
            "Topic 3: shortly black accomplished instead specifies rise invariance shrink lausanne maintain\n",
            "Topic 4: orders saw regressors phrase star observes sapiro impression morgan formal\n",
            "Topic 5: agglomerative together separation tenenbaum cauchy interscience animals environment mild berkeley\n",
            "Topic 6: syst tendency describing completed opposed capable lambda restaurant riding prevalence\n",
            "Topic 7: segments location lemmas static treated connected generative diagnostic sphere contribution\n",
            "Topic 8: speaker darpa refinement shamir schneider adversarial vary altun savings may\n",
            "Topic 9: overhead clearly platform ibp ronald evaluations extensions jacobian typically chapelle\n",
            "Step: 4000 Loss: -3479704576.000 (0.194 sec)\n",
            "Negative log-likelihood <= 3479704576.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: reward conference alarm advance highlighted similarly projecting sources semantics date\n",
            "Topic 1: write dan optimised category advantages opportunity issues play aggregated tries\n",
            "Topic 2: comprehensive forms cessing valuable ancestors tails critic indexing raises phys\n",
            "Topic 3: shortly black accomplished instead specifies rise invariance lausanne shrink maintain\n",
            "Topic 4: orders saw regressors phrase star observes sapiro impression morgan formal\n",
            "Topic 5: agglomerative together separation tenenbaum cauchy interscience environment animals mild lle\n",
            "Topic 6: syst tendency describing completed opposed capable lambda restaurant riding prevalence\n",
            "Topic 7: segments location lemmas static treated connected generative sphere diagnostic contribution\n",
            "Topic 8: darpa speaker refinement schneider shamir adversarial vary altun savings gupta\n",
            "Topic 9: clearly overhead platform ibp ronald evaluations extensions jacobian typically chapelle\n",
            "Step: 4500 Loss: -3342118656.000 (0.199 sec)\n",
            "Negative log-likelihood <= 3342118656.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: alarm conference reward advance highlighted similarly projecting sources semantics date\n",
            "Topic 1: dan write optimised category advantages opportunity issues play aggregated tries\n",
            "Topic 2: comprehensive forms valuable cessing tails ancestors critic indexing raises phys\n",
            "Topic 3: shortly accomplished black instead specifies rise invariance lausanne shrink sugiyama\n",
            "Topic 4: orders saw regressors star phrase sapiro observes impression morgan formal\n",
            "Topic 5: agglomerative together separation cauchy tenenbaum interscience environment animals mild berkeley\n",
            "Topic 6: tendency describing syst completed opposed lambda capable riding restaurant prevalence\n",
            "Topic 7: segments location lemmas static treated connected generative diagnostic sphere contribution\n",
            "Topic 8: speaker darpa refinement shamir schneider adversarial vary savings altun may\n",
            "Topic 9: clearly overhead platform ibp ronald evaluations extensions jacobian typically chapelle\n",
            "Step: 5000 Loss: -2515166208.000 (0.200 sec)\n",
            "Negative log-likelihood <= 2515166208.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: reward conference advance alarm highlighted projecting similarly sources semantics date\n",
            "Topic 1: dan write advantages optimised category play issues opportunity aggregated tries\n",
            "Topic 2: comprehensive forms tails cessing valuable ancestors critic indexing raises parametric\n",
            "Topic 3: shortly black accomplished rise instead specifies invariance maintain sugiyama lausanne\n",
            "Topic 4: orders saw regressors phrase sapiro star observes morgan impression formal\n",
            "Topic 5: together agglomerative separation tenenbaum cauchy interscience animals environment mild lle\n",
            "Topic 6: syst tendency completed opposed describing lambda capable restaurant prevalence riding\n",
            "Topic 7: segments location lemmas static connected treated generative diagnostic digit sphere\n",
            "Topic 8: darpa speaker refinement schneider shamir vary adversarial altun savings may\n",
            "Topic 9: platform clearly overhead ibp ronald extensions evaluations jacobian typically dirichlet\n",
            "Step: 5500 Loss: -4307383808.000 (0.195 sec)\n",
            "Negative log-likelihood <= 4307383808.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: alarm reward advance conference highlighted projecting similarly sources semantics date\n",
            "Topic 1: write dan optimised play advantages category opportunity issues tries aggregated\n",
            "Topic 2: comprehensive forms cessing tails valuable ancestors critic raises indexing parametric\n",
            "Topic 3: accomplished black shortly rise instead specifies invariance maintain lausanne sugiyama\n",
            "Topic 4: orders regressors saw phrase observes star impression sapiro site formal\n",
            "Topic 5: agglomerative together cauchy tenenbaum separation animals interscience environment mild berkeley\n",
            "Topic 6: tendency syst describing capable opposed completed lambda restaurant prevalence riding\n",
            "Topic 7: location segments lemmas static treated connected sphere contribution generative diagnostic\n",
            "Topic 8: speaker darpa schneider shamir refinement adversarial vary kmax savings gupta\n",
            "Topic 9: clearly platform ibp overhead ronald typically extensions jacobian evaluations chapelle\n",
            "Step: 6000 Loss: -2001774976.000 (0.194 sec)\n",
            "Negative log-likelihood <= 2001774976.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: advance conference reward highlighted alarm similarly projecting semantics sources date\n",
            "Topic 1: advantages write optimised opportunity play category issues dan responds separates\n",
            "Topic 2: valuable forms cessing tails comprehensive ancestors critic indexing raises coda\n",
            "Topic 3: shortly invariance accomplished black instead specifies rise sugiyama shrink maintain\n",
            "Topic 4: regressors saw orders phrase star impression sapiro formal morgan observes\n",
            "Topic 5: agglomerative separation tenenbaum cauchy together interscience environment mild animals berkeley\n",
            "Topic 6: tendency lambda syst completed opposed describing capable restaurant prevalence riding\n",
            "Topic 7: lemmas segments location static sphere diagnostic generative treated connected imposed\n",
            "Topic 8: speaker darpa adversarial shamir refinement schneider vary savings may approximating\n",
            "Topic 9: ronald clearly overhead platform ibp typically extensions evaluations jacobian unnormalized\n",
            "Step: 6500 Loss: -2709362688.000 (0.194 sec)\n",
            "Negative log-likelihood <= 2709362688.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: reward advance conference highlighted alarm sources similarly semantics date projecting\n",
            "Topic 1: optimised issues play advantages opportunity dan write category target responds\n",
            "Topic 2: valuable forms cessing ancestors tails critic comprehensive raises indexing gathered\n",
            "Topic 3: maintain shortly accomplished specifies lausanne black rise invariance instead shrink\n",
            "Topic 4: regressors saw orders phrase star observes sapiro impression site morgan\n",
            "Topic 5: cauchy separation tenenbaum interscience agglomerative together malicious environment collaborative berkeley\n",
            "Topic 6: describing syst completed opposed capable lambda tendency riding restaurant hall\n",
            "Topic 7: treated location lemmas segments connected static imposed lane sphere symbol\n",
            "Topic 8: speaker darpa refinement adversarial savings altun vary may kmax shamir\n",
            "Topic 9: overhead platform ibp evaluations ronald clearly extensions dirichlet jacobian interna\n",
            "Step: 7000 Loss: -2989526016.000 (0.192 sec)\n",
            "Negative log-likelihood <= 2989526016.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 7500 Loss: -3075129856.000 (0.201 sec)\n",
            "Negative log-likelihood <= 3075129856.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 8000 Loss: -2781060096.000 (0.192 sec)\n",
            "Negative log-likelihood <= 2781060096.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 8500 Loss: -2486332160.000 (0.194 sec)\n",
            "Negative log-likelihood <= 2486332160.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 9000 Loss: -2783167744.000 (0.195 sec)\n",
            "Negative log-likelihood <= 2783167744.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 9500 Loss: -2822178816.000 (0.197 sec)\n",
            "Negative log-likelihood <= 2822178816.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 10000 Loss: -2480666112.000 (0.197 sec)\n",
            "Negative log-likelihood <= 2480666112.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 10500 Loss: -3283739648.000 (0.196 sec)\n",
            "Negative log-likelihood <= 3283739648.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 11000 Loss: -2865249280.000 (0.194 sec)\n",
            "Negative log-likelihood <= 2865249280.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 11500 Loss: -4041821184.000 (0.196 sec)\n",
            "Negative log-likelihood <= 4041821184.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 12000 Loss: -5035606528.000 (0.193 sec)\n",
            "Negative log-likelihood <= 5035606528.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 12500 Loss: -2820999936.000 (0.199 sec)\n",
            "Negative log-likelihood <= 2820999936.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 13000 Loss: -3611003392.000 (0.193 sec)\n",
            "Negative log-likelihood <= 3611003392.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 13500 Loss: -1950852864.000 (0.193 sec)\n",
            "Negative log-likelihood <= 1950852864.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 14000 Loss: -3383941632.000 (0.194 sec)\n",
            "Negative log-likelihood <= 3383941632.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 14500 Loss: -3365831424.000 (0.194 sec)\n",
            "Negative log-likelihood <= 3365831424.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 15000 Loss: -2614160384.000 (0.194 sec)\n",
            "Negative log-likelihood <= 2614160384.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 15500 Loss: -2270510848.000 (0.194 sec)\n",
            "Negative log-likelihood <= 2270510848.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 16000 Loss: -3066497280.000 (0.192 sec)\n",
            "Negative log-likelihood <= 3066497280.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 16500 Loss: -2839941376.000 (0.194 sec)\n",
            "Negative log-likelihood <= 2839941376.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 17000 Loss: -3538903552.000 (0.196 sec)\n",
            "Negative log-likelihood <= 3538903552.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 17500 Loss: -2593235200.000 (0.193 sec)\n",
            "Negative log-likelihood <= 2593235200.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 18000 Loss: -3381399552.000 (0.194 sec)\n",
            "Negative log-likelihood <= 3381399552.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 18500 Loss: -3155192576.000 (0.193 sec)\n",
            "Negative log-likelihood <= 3155192576.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 19000 Loss: -3594077440.000 (0.195 sec)\n",
            "Negative log-likelihood <= 3594077440.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Step: 19500 Loss: -1741131776.000 (0.194 sec)\n",
            "Negative log-likelihood <= 1741131776.000\n",
            "Perplexity <= inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Topic 0: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 1: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 2: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 3: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 4: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 5: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 6: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 7: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 8: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n",
            "Topic 9: zurich fails factorisation factorization factorizations factorize factorized factorizes factors facts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i5bhRDEtOYc5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "\n",
        "As we can see, with the decreasing negative log-likelihood we get lists of words that seem to be more intuitively separable in to the various topics. Granted, these topics don't have names themselves, but this separation is clear.\n",
        "\n",
        "With default settings (in particular, with $\\text{log-Normal}$ variational approximation), this model takes ~62 seconds per epoch on a Titan X (Pascal). The following results are on epoch 12.\n",
        "\n",
        "**Topic 0:** `let distribution set strategy distributions given learning information use property`\n",
        "    \n",
        "**Topic 1:** `functions problem risk function submodular cut level clustering sets performance`\n",
        "\n",
        "**Topic 2:** `action value learning regret reward actions algorithm optimal state return`\n",
        "\n",
        "**Topic 3:** `posterior stochastic approach information based using prior\n",
        "    mean divergence since`\n",
        "\n",
        "**Topic 4:** `player inference game propagation experts static query expert\n",
        "    base variables`\n",
        "\n",
        "**Topic 5:** `algorithm set loss weak algorithms optimal submodular online\n",
        "    cost setting`\n",
        "\n",
        "**Topic 6:** `sparse sparsity norm solution learning penalty greedy\n",
        "    structure wise regularization`\n",
        "\n",
        "**Topic 7:** `learning training linear kernel using coding accuracy\n",
        "    performance dataset based`\n",
        "\n",
        "**Topic 8:** `object categories image features examples classes images\n",
        "    class objects visual`\n",
        "\n",
        "**Topic 9:** `data manifold matrix points dimensional point low linear\n",
        "    gradient optimization`\n",
        "\n",
        "If we use a $\\text{Gamma}$ variational approximation (instead of a $\\text{log-Normal}$ approximation) , this produces worse results. This is likely due to the high variance in stochastic gradients. The $\\text{Gamma}$ version takes ~2 minutes per epoch on a Titan X (Pascal). This is what the results look like on epoch 12.\n",
        "\n",
        "**Topic 0:** `reasons posterior tion using similar tools university input computed refers`\n",
        "\n",
        "**Topic 1:** `expected since much related rate defined optimization vector thus neurons`\n",
        "\n",
        "**Topic 2:** `large linear given table shown true drop classification constraints current`\n",
        "\n",
        "**Topic 3:** `proposed processing estimated better values gaussian form test true setting`\n",
        "\n",
        "**Topic 4:** `see methods local several rate processing general vector enables section`\n",
        "\n",
        "**Topic 5:** `thus case methods image dataset models different instead new respectively`\n",
        "\n",
        "**Topic 6:** `based consider samples step object see kernel since problem training`\n",
        "\n",
        "**Topic 7:** `approaches linear computing show gaussian data expected analysis well proof`\n",
        "\n",
        "**Topic 8:** `fig point kernel bayesian solution applications results follows regression computer`\n",
        "\n",
        "**Topic 9:** `conference optimization training pages maximum learning dataset performance state inference`"
      ]
    },
    {
      "metadata": {
        "id": "VA1I7Jf-RHH5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "\n",
        "[1] Michael Figurnov, Shakir Mohamed, Andriy Mnih. [\"Implicit Reparameterization Gradients, 2018\"](https://arxiv.org/abs/1805.08498). https://arxiv.org/abs/1805.08498.\n",
        "     \n",
        "[2] Valerio Perrone and Paul A Jenkins and Dario Spano and Yee Whye Teh. [Poisson Random Fields for Dynamic Feature Models](https://arxiv.org/abs/1611.07460), 2016. https://arxiv.org/abs/1611.07460\n",
        "     \n",
        "[3] Rajesh Ranganath, Linpeng Tang, Laurent Charlin, David M. Blei. [Deep exponential families.](http://www.cs.toronto.edu/~lcharlin/papers/def_aistats.pdf) In _Artificial Intelligence and Statistics_, 2015. https://arxiv.org/abs/1411.2581\n",
        "\n",
        "Other code examples:\n",
        "- [The existing (Edward2) TFP Example](https://github.com/tensorflow/probability/blob/22cb49d4b7d70a96a46f3a230792eab7ef793cb8/tensorflow_probability/examples/deep_exponential_family.py)\n",
        "- [Deep Exponential Family in Gluon](https://github.com/altosaar/deep-exponential-families-gluon)\n",
        "- [A fork of the Blei Lab example](https://github.com/mkturkcan/DEF-val/blob/dbaf43c8b76f789e9630b9d8b6085cae463cbc9b/DEF-val.py)\n",
        "\n"
      ]
    }
  ]
}